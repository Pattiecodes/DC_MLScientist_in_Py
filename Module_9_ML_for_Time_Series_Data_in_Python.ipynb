{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtVO2hxBDKN//You2hGiw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_9_ML_for_Time_Series_Data_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "0pFPHMPovtsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting a time series (I)\n",
        "In this exercise, you'll practice plotting the values of two time series without the time component.\n",
        "\n",
        "Two DataFrames, data and data2 are available in your workspace.\n",
        "\n",
        "Unless otherwise noted, assume that all required packages are loaded with their common aliases throughout this course.\n",
        "\n",
        "Note: This course assumes some familiarity with time series data, as well as how to use them in data analytics pipelines. For an introduction to time series, we recommend the Introduction to Time Series Analysis in Python and Visualizing Time Series Data with Python courses.\n",
        "\n",
        "Instructions 1/3\n",
        "15 XP\n",
        "2\n",
        "3\n",
        "Print the first five rows of data."
      ],
      "metadata": {
        "id": "gLAdHxee8tqA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMKlfcSUvlC_"
      },
      "outputs": [],
      "source": [
        "# Print the first 5 rows of data\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "15 XP\n",
        "3\n",
        "Print the first five rows of data2."
      ],
      "metadata": {
        "id": "gDJ-X2mc82I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 rows of data2\n",
        "print(data2.head())"
      ],
      "metadata": {
        "id": "xtqWTD3x82vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "70 XP\n",
        "Plot the values column of both the data sets on top of one another, one per axis object."
      ],
      "metadata": {
        "id": "1GQpXO1c-rOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the time series in each dataset\n",
        "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
        "data.iloc[:1000].plot(y='data_values', ax=axs[0])\n",
        "data2.iloc[:1000].plot(y='data_values', ax=axs[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SqB_6b8N-r5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting a time series (II)\n",
        "You'll now plot both the datasets again, but with the included time stamps for each (stored in the column called \"time\"). Let's see if this gives you some more context for understanding each time series data.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Plot data and data2 on top of one another, one per axis object.\n",
        "The x-axis should represent the time stamps and the y-axis should represent the dataset values.\n"
      ],
      "metadata": {
        "id": "J1svoUELAaxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the time series in each dataset\n",
        "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
        "data.iloc[:1000].plot(x='time', y='data_values', ax=axs[0])\n",
        "data2.iloc[:1000].plot(x='time', y='data_values', ax=axs[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rR4MFyySAbCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a simple model: classification\n",
        "In this exercise, you'll use the iris dataset (representing petal characteristics of a number of flowers) to practice using the scikit-learn API to fit a classification model. You can see a sample plot of the data to the right.\n",
        "\n",
        "Note: This course assumes some familiarity with Machine Learning and scikit-learn. For an introduction to scikit-learn, we recommend the Supervised Learning with Scikit-Learn and Preprocessing for Machine Learning in Python courses.\n",
        "\n",
        "Instructions 1/2\n",
        "10 XP\n",
        "2\n",
        "Print the first five rows of data."
      ],
      "metadata": {
        "id": "B-6Re_k02zhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 rows for inspection\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "wgcCWpwD2z9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "90 XP\n",
        "2\n",
        "Extract the \"petal length (cm)\" and \"petal width (cm)\" columns of data and assign it to X.\n",
        "Fit a model on X and y."
      ],
      "metadata": {
        "id": "t6u4doP923az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Construct data for the model\n",
        "X = data[[\"petal length (cm)\", \"petal width (cm)\"]]\n",
        "y = data[['target']]\n",
        "\n",
        "# Fit the model\n",
        "model = LinearSVC()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "Uy3lsNYY23ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting using a classification model\n",
        "Now that you have fit your classifier, let's use it to predict the type of flower (or class) for some newly-collected flowers.\n",
        "\n",
        "Information about petal width and length for several new flowers is stored in the variable targets. Using the classifier you fit, you'll predict the type of each flower.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Predict the flower type using the array X_predict.\n",
        "Run the given code to visualize the predictions."
      ],
      "metadata": {
        "id": "rlCPBp1d3eWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input array\n",
        "X_predict = targets[['petal length (cm)', 'petal width (cm)']]\n",
        "\n",
        "# Predict with the model\n",
        "predictions = model.predict(X_predict)\n",
        "print(predictions)\n",
        "\n",
        "# Visualize predictions and actual values\n",
        "plt.scatter(X_predict['petal length (cm)'], X_predict['petal width (cm)'],\n",
        "            c=predictions, cmap=plt.cm.coolwarm)\n",
        "plt.title(\"Predicted class values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MdMgSeWN3erN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a simple model: regression\n",
        "In this exercise, you'll practice fitting a regression model using data from the California housing market. A DataFrame called housing is available in your workspace. It contains many variables of data (stored as columns). Can you find a relationship between the following two variables?\n",
        "\n",
        "\"MedHouseVal\": the median house value for California districts (in $100,000s of dollars)\n",
        "\"AveRooms\" : average number of rooms per dwelling\n",
        "Instructions\n",
        "100 XP\n",
        "Prepare X and y DataFrames using the data in housing.\n",
        "X should be the Median House Value, y average number of rooms per dwelling.\n",
        "Fit a regression model that uses these variables (remember to shape the variables correctly!).\n",
        "Don't forget that each variable must be the correct shape for scikit-learn to use it!"
      ],
      "metadata": {
        "id": "3aTME2gH1MoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "# Prepare input and output DataFrames\n",
        "X = housing[[\"MedHouseVal\"]]\n",
        "y = housing[[\"AveRooms\"]]\n",
        "\n",
        "# Fit the model\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "TRKfTuOX1NPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting using a regression model\n",
        "Now that you've fit a model with the California housing data, lets see what predictions it generates on some new data. You can investigate the underlying relationship that the model has found between inputs and outputs by feeding in a range of numbers as inputs and seeing what the model predicts for each input.\n",
        "\n",
        "A 1-D array new_inputs consisting of 100 \"new\" values for \"MedHouseVal\" (median house value) is available in your workspace along with the model you fit in the previous exercise.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Review new_inputs in the shell.\n",
        "Reshape new_inputs appropriately to generate predictions.\n",
        "Run the given code to visualize the predictions."
      ],
      "metadata": {
        "id": "O4_y3BP11z0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions with the model using those inputs\n",
        "predictions = model.predict(new_inputs.reshape(-1, 1))\n",
        "\n",
        "# Visualize the inputs and predicted values\n",
        "plt.scatter(new_inputs, predictions, color='r', s=3)\n",
        "plt.xlabel('inputs')\n",
        "plt.ylabel('predictions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nFDBPn9q15_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the classification data\n",
        "In these final exercises of this chapter, you'll explore the two datasets you'll use in this course.\n",
        "\n",
        "The first is a collection of heartbeat sounds. Hearts normally have a predictable sound pattern as they beat, but some disorders can cause the heart to beat abnormally. This dataset contains a training set with labels for each type of heartbeat, and a testing set with no labels. You'll use the testing set to validate your models.\n",
        "\n",
        "As you have labeled data, this dataset is ideal for classification. In fact, it was originally offered as a part of a public Kaggle competition.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Use glob to return a list of the .wav files in data_dir directory.\n",
        "Import the first audio file in the list using librosa.\n",
        "Generate a time array for the data.\n",
        "Plot the waveform for this file, along with the time array."
      ],
      "metadata": {
        "id": "3WmqzY2eMevR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa as lr\n",
        "from glob import glob\n",
        "\n",
        "# List all the wav files in the folder\n",
        "audio_files = glob(data_dir + '/*.wav')\n",
        "\n",
        "# Read in the first audio file, create the time array\n",
        "audio, sfreq = lr.load(audio_files[0])\n",
        "time = np.arange(0, len(audio)) / sfreq\n",
        "\n",
        "# Plot audio over time\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(time, audio)\n",
        "ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DkM9SfLbMfYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the regression data\n",
        "The next dataset contains information about company market value over several years of time. This is one of the most popular kind of time series data used for regression. If you can model the value of a company as it changes over time, you can make predictions about where that company will be in the future. This dataset was also originally provided as part of a public Kaggle competition.\n",
        "\n",
        "In this exercise, you'll plot the time series for a number of companies to get an understanding of how they are (or aren't) related to one another.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the data with Pandas (stored in the file 'prices.csv').\n",
        "Convert the index of data to datetime.\n",
        "Loop through each column of data and plot the the column's values over time."
      ],
      "metadata": {
        "id": "FasDnwSRNWFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the data\n",
        "data = pd.read_csv('prices.csv', index_col=0)\n",
        "\n",
        "# Convert the index of the DataFrame to datetime\n",
        "data.index = pd.to_datetime(data.index)\n",
        "print(data.head())\n",
        "\n",
        "# Loop through each column, plot its values over time\n",
        "fig, ax = plt.subplots()\n",
        "for column in data:\n",
        "    data[column].plot(ax=ax, label=column)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E1eF-M9sNWbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Many repetitions of sounds\n",
        "In this exercise, you'll start with perhaps the simplest classification technique: averaging across dimensions of a dataset and visually inspecting the result.\n",
        "\n",
        "You'll use the heartbeat data described in the last chapter. Some recordings are normal heartbeat activity, while others are abnormal activity. Let's see if you can spot the difference.\n",
        "\n",
        "Two DataFrames, normal and abnormal, each with the shape of (n_times_points, n_audio_files) containing the audio for several heartbeats are available in your workspace. Also, the sampling frequency is loaded into a variable called sfreq. A convenience plotting function show_plot_and_make_titles() is also available in your workspace.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "First, create the time array for these audio files (all audios are the same length).\n",
        "Then, stack the values of the two DataFrames together (normal and abnormal, in that order) so that you have a single array of shape (n_audio_files, n_times_points).\n",
        "Finally, use the code provided to loop through each list item / axis, and plot the audio over time in the corresponding axis object.\n",
        "You'll plot normal heartbeats in the left column, and abnormal ones in the right column"
      ],
      "metadata": {
        "id": "iD8BhGqdNvcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n",
        "\n",
        "# Calculate the time array\n",
        "time = np.arange(normal.shape[0]) / sfreq\n",
        "\n",
        "# Stack the normal/abnormal audio so you can loop and plot\n",
        "stacked_audio = np.hstack([normal, abnormal]).T\n",
        "\n",
        "# Loop through each audio file / ax object and plot\n",
        "# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\n",
        "for iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n",
        "    ax.plot(time, iaudio)\n",
        "show_plot_and_make_titles()"
      ],
      "metadata": {
        "id": "11K2CskSNxbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invariance in time\n",
        "While you should always start by visualizing your raw data, this is often uninformative when it comes to discriminating between two classes of data points. Data is usually noisy or exhibits complex patterns that aren't discoverable by the naked eye.\n",
        "\n",
        "Another common technique to find simple differences between two sets of data is to average across multiple instances of the same class. This may remove noise and reveal underlying patterns (or, it may not).\n",
        "\n",
        "In this exercise, you'll average across many instances of each class of heartbeat sound.\n",
        "\n",
        "The two DataFrames (normal and abnormal) and the time array (time) from the previous exercise are available in your workspace.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Average across the audio files contained in normal and abnormal, leaving the time dimension.\n",
        "Visualize these averages over time."
      ],
      "metadata": {
        "id": "qhBD8JWjUR69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average across the audio files of each DataFrame\n",
        "mean_normal = np.mean(normal, axis=1)\n",
        "mean_abnormal = np.mean(abnormal, axis=1)\n",
        "\n",
        "# Plot each average over time\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
        "ax1.plot(time, mean_normal)\n",
        "ax1.set(title=\"Normal Data\")\n",
        "ax2.plot(time, mean_abnormal)\n",
        "ax2.set(title=\"Abnormal Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V_GUvI2YUSXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a classification model\n",
        "While eye-balling differences is a useful way to gain an intuition for the data, let's see if you can operationalize things with a model. In this exercise, you will use each repetition as a datapoint, and each moment in time as a feature to fit a classifier that attempts to predict abnormal vs. normal heartbeats using only the raw data.\n",
        "\n",
        "We've split the two DataFrames (normal and abnormal) into X_train, X_test, y_train, and y_test.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create an instance of the Linear SVC model and fit the model using the training data.\n",
        "Use the testing data to generate predictions with the model.\n",
        "Score the model using the provided code."
      ],
      "metadata": {
        "id": "IQ4H2_c9U-qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Initialize and fit the model\n",
        "model = LinearSVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions and score them manually\n",
        "predictions = model.predict(X_test)\n",
        "print(sum(predictions == y_test.squeeze()) / len(y_test))"
      ],
      "metadata": {
        "id": "8UybAQxCU-8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating the envelope of sound\n",
        "One of the ways you can improve the features available to your model is to remove some of the noise present in the data. In audio data, a common way to do this is to smooth the data and then rectify it so that the total amount of sound energy over time is more distinguishable. You'll do this in the current exercise.\n",
        "\n",
        "A heartbeat file is available in the variable audio.\n",
        "\n",
        "Instructions 1/3\n",
        "33 XP\n",
        "2\n",
        "3\n",
        "Visualize the raw audio you'll use to calculate the envelope."
      ],
      "metadata": {
        "id": "RG8_76a2hcHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the raw data first\n",
        "audio.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aQs4X5YphdS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "33 XP\n",
        "3\n",
        "Rectify the audio.\n",
        "Plot the result."
      ],
      "metadata": {
        "id": "Sko7_wdThwq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rectify the audio signal\n",
        "audio_rectified = audio.apply(np.abs)\n",
        "\n",
        "# Plot the result\n",
        "audio_rectified.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hZsVGI50hxNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "34 XP\n",
        "Smooth the audio file by applying a rolling mean.\n",
        "Plot the result."
      ],
      "metadata": {
        "id": "rhZgxHzih_FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smooth by applying a rolling mean\n",
        "audio_rectified_smooth = audio_rectified.rolling(50).mean()\n",
        "\n",
        "# Plot the result\n",
        "audio_rectified_smooth.plot(figsize=(10, 5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZNZ-fa2eh_hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating features from the envelope\n",
        "Now that you've removed some of the noisier fluctuations in the audio, let's see if this improves your ability to classify.\n",
        "\n",
        "audio_rectified_smooth from the previous exercise is available in your workspace.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Calculate the mean, standard deviation, and maximum value for each heartbeat sound.\n",
        "Column stack these stats in the same order.\n",
        "Use cross-validation to fit a model on each CV iteration."
      ],
      "metadata": {
        "id": "yHnjCJ7qieNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate stats\n",
        "means = np.mean(audio_rectified_smooth, axis=0)\n",
        "stds = np.std(audio_rectified_smooth, axis=0)\n",
        "maxs = np.max(audio_rectified_smooth, axis=0)\n",
        "\n",
        "# Create the X and y arrays\n",
        "X = np.column_stack([means, stds, maxs])\n",
        "y = labels.reshape(-1, 1)\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "from sklearn.model_selection import cross_val_score\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "metadata": {
        "id": "PYVd4g3miejW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Derivative features: The tempogram\n",
        "One benefit of cleaning up your data is that it lets you compute more sophisticated features. For example, the envelope calculation you performed is a common technique in computing tempo and rhythm features. In this exercise, you'll use librosa to compute some tempo and rhythm features for heartbeat data, and fit a model once more.\n",
        "\n",
        "Note that librosa functions tend to only operate on numpy arrays instead of DataFrames, so we'll access our Pandas data as a Numpy array with the .values attribute.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Use librosa to calculate a tempogram of each heartbeat audio.\n",
        "Calculate the mean, standard deviation, and maximum of each tempogram (this time using DataFrame methods)\n"
      ],
      "metadata": {
        "id": "utnAzMp4ym80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the tempo of the sounds\n",
        "tempos = []\n",
        "for col, i_audio in audio.items():\n",
        "    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))\n",
        "\n",
        "# Convert the list to an array so you can manipulate it more easily\n",
        "tempos = np.array(tempos)\n",
        "\n",
        "# Calculate statistics of each tempo\n",
        "tempos_mean = tempos.mean(axis=-1)\n",
        "tempos_std = tempos.std(axis=-1)\n",
        "tempos_max = tempos.max(axis=-1)"
      ],
      "metadata": {
        "id": "l90nnJbVynW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "Column stack these tempo features (mean, standard deviation, and maximum) in the same order.\n",
        "Score the classifier with cross-validation."
      ],
      "metadata": {
        "id": "W9fytscczPDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the X and y arrays\n",
        "X = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])\n",
        "y = labels.reshape(-1, 1)\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "metadata": {
        "id": "hBsjIPDvzPNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spectrograms of heartbeat audio\n",
        "Spectral engineering is one of the most common techniques in machine learning for time series data. The first step in this process is to calculate a spectrogram of sound. This describes what spectral content (e.g., low and high pitches) are present in the sound over time. In this exercise, you'll calculate a spectrogram of a heartbeat audio file.\n",
        "\n",
        "We've loaded a single heartbeat sound in the variable audio.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Import the short-time fourier transform (stft) function from librosa.core.\n",
        "Calculate the spectral content (using the short-time fourier transform function) of audio."
      ],
      "metadata": {
        "id": "iQtYKGbWkChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the stft function\n",
        "from librosa.core import stft\n",
        "\n",
        "# Prepare the STFT\n",
        "HOP_LENGTH = 2**4\n",
        "spec = stft(audio, hop_length=HOP_LENGTH, n_fft=2**7)"
      ],
      "metadata": {
        "id": "X9hLhAhOkC3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "Convert the spectogram (spec) to decibels.\n",
        "Visualize the spectogram."
      ],
      "metadata": {
        "id": "AZwLJwL2kage"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from librosa.core import amplitude_to_db\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Convert into decibels\n",
        "spec_db = amplitude_to_db(spec)\n",
        "\n",
        "# Compare the raw audio to the spectrogram of the audio\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\n",
        "axs[0].plot(time, audio)\n",
        "specshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH, ax=axs[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mk6uBA78kaqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Engineering spectral features\n",
        "As you can probably tell, there is a lot more information in a spectrogram compared to a raw audio file. By computing the spectral features, you have a much better idea of what's going on. As such, there are all kinds of spectral features that you can compute using the spectrogram as a base. In this exercise, you'll look at a few of these features.\n",
        "\n",
        "The spectogram spec from the previous exercise is available in your workspace.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Calculate the spectral bandwidth as well as the spectral centroid of the spectrogram by using functions in librosa.feature."
      ],
      "metadata": {
        "id": "auEJ7-Lvsbrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa as lr\n",
        "\n",
        "# Calculate the spectral centroid and bandwidth for the spectrogram\n",
        "bandwidths = lr.feature.spectral_bandwidth(S=spec)[0]\n",
        "centroids = lr.feature.spectral_centroid(S=spec)[0]"
      ],
      "metadata": {
        "id": "1XaeRDpascZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "Convert the spectrogram to decibels for visualization.\n",
        "Plot the spectrogram over time."
      ],
      "metadata": {
        "id": "iqLcSLMwtiJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from librosa.core import amplitude_to_db\n",
        "from librosa.display import specshow\n",
        "\n",
        "# Convert spectrogram to decibels for visualization\n",
        "spec_db = amplitude_to_db(spec)\n",
        "\n",
        "# Display these features on top of the spectrogram\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "specshow(spec_db, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH, ax=ax)\n",
        "ax.plot(times_spec, centroids)\n",
        "ax.fill_between(times_spec, centroids - bandwidths / 2, centroids + bandwidths / 2, alpha=.5)\n",
        "ax.set(ylim=[None, 6000])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BYSa54qetihg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining many features in a classifier\n",
        "You've spent this lesson engineering many features from the audio data - some contain information about how the audio changes in time, others contain information about the spectral content that is present.\n",
        "\n",
        "The beauty of machine learning is that it can handle all of these features at the same time. If there is different information present in each feature, it should improve the classifier's ability to distinguish the types of audio. Note that this often requires more advanced techniques such as regularization, which we'll cover in the next chapter.\n",
        "\n",
        "For the final exercise in the chapter, we've loaded many of the features that you calculated before. Combine all of them into an array that can be fed into the classifier, and see how it does.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Loop through each spectrogram, calculating the mean spectral bandwidth and centroid of each."
      ],
      "metadata": {
        "id": "fwh3gMeRxHlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each spectrogram\n",
        "bandwidths = []\n",
        "centroids = []\n",
        "\n",
        "for spec in spectrograms:\n",
        "    # Calculate the mean spectral bandwidth\n",
        "    this_mean_bandwidth = np.mean(lr.feature.spectral_bandwidth(S=spec))\n",
        "    # Calculate the mean spectral centroid\n",
        "    this_mean_centroid = np.mean(lr.feature.spectral_centroid(S=spec))\n",
        "    # Collect the values\n",
        "    bandwidths.append(this_mean_bandwidth)\n",
        "    centroids.append(this_mean_centroid)"
      ],
      "metadata": {
        "id": "mXVR4m0ExIGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "Column stack all the features to create the array X.\n",
        "Score the classifier with cross-validation."
      ],
      "metadata": {
        "id": "PkJ0TIPyy14E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y arrays\n",
        "X = np.column_stack([means, stds, maxs, tempo_mean, tempo_max, tempo_std, bandwidths, centroids])\n",
        "y = labels.reshape(-1, 1)\n",
        "\n",
        "# Fit the model and score on testing data\n",
        "percent_score = cross_val_score(model, X, y, cv=5)\n",
        "print(np.mean(percent_score))"
      ],
      "metadata": {
        "id": "xuEV0WKIy2NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing the dataset\n",
        "As mentioned in the video, you'll deal with stock market prices that fluctuate over time. In this exercise you've got historical prices from two tech companies (Ebay and Yahoo) in the DataFrame prices. You'll visualize the raw data for the two companies, then generate a scatter plot showing how the values for each company compare with one another. Finally, you'll add in a \"time\" dimension to your scatter plot so you can see how this relationship changes over time.\n",
        "\n",
        "The data has been loaded into a DataFrame called prices.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Plot the data in prices. Pay attention to any irregularities you notice."
      ],
      "metadata": {
        "id": "TddbTCY96B2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the raw values over time\n",
        "prices.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y3VO0LtS6fRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Generate a scatter plot with the values of Ebay on the x-axis, and Yahoo on the y-axis. Look up the symbols for both companies from the column names of the DataFrame."
      ],
      "metadata": {
        "id": "PAE-7Hz56iC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot with one company per axis\n",
        "prices.plot.scatter('EBAY', 'YHOO')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rRGW_KFn6jfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "\n",
        "Finally, encode time as the color of each datapoint in order to visualize how the relationship between these two variables changes."
      ],
      "metadata": {
        "id": "-Qb5tGjT6-Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatterplot with color relating to time\n",
        "prices.plot.scatter('EBAY', 'YHOO', c=prices.index, cmap=plt.cm.viridis, colorbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n0nTvuJ76_Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a simple regression model\n",
        "Now we'll look at a larger number of companies. Recall that we have historical price values for many companies. Let's use data from several companies to predict the value of a test company. You'll attempt to predict the value of the Apple stock price using the values of NVidia, Ebay, and Yahoo. Each of these is stored as a column in the all_prices DataFrame. Below is a mapping from company name to column name:\n",
        "```\n",
        "ebay: \"EBAY\"\n",
        "nvidia: \"NVDA\"\n",
        "yahoo: \"YHOO\"\n",
        "apple: \"AAPL\"\n",
        "We'll use these columns to define the input/output arrays in our model.\n",
        "```\n",
        "Instructions\n",
        "100 XP\n",
        "Create the X and y arrays by using the column names provided.\n",
        "The input values should be from the companies \"ebay\", \"nvidia\", and \"yahoo\"\n",
        "The output values should be from the company \"apple\"\n",
        "Use the data to train and score the model with cross-validation."
      ],
      "metadata": {
        "id": "pFFC8THY3_ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Use stock symbols to extract training data\n",
        "X = all_prices[['EBAY', 'NVDA', 'YHOO']]\n",
        "y = all_prices[['AAPL']]\n",
        "\n",
        "# Fit and score the model with cross-validation\n",
        "scores = cross_val_score(Ridge(), X, y, cv=3)\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "hR6gzdM-4BIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing predicted values\n",
        "When dealing with time series data, it's useful to visualize model predictions on top of the \"actual\" values that are used to test the model.\n",
        "\n",
        "In this exercise, after splitting the data (stored in the variables X and y) into training and test sets, you'll build a model and then visualize the model's predictions on top of the testing data in order to estimate the model's performance.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Split the data (X and y) into training and test sets.\n",
        "Use the training data to train the regression model.\n",
        "Then use the testing data to generate predictions for the model."
      ],
      "metadata": {
        "id": "MCmlgqPk4cSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Split our data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    train_size=.8, shuffle=False)\n",
        "\n",
        "# Fit our model and generate predictions\n",
        "model = Ridge()\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "score = r2_score(y_test, predictions)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "RggQlglv4cl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "Plot a time series of the predicted and \"actual\" values of the testing data."
      ],
      "metadata": {
        "id": "2mUEtQ3y4zNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize our predictions along with the \"true\" values, and print the score\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.plot(y_test, color='k', lw=3)\n",
        "ax.plot(predictions, color='r', lw=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IaJ3tibp4ziA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}