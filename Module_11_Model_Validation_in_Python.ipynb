{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM09RMZDXL1wt8W+JEi6GcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_11_Model_Validation_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "UJ62fyG8Zh2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seen vs. unseen data\n",
        "Model's tend to have higher accuracy on observations they have seen before. In the candy dataset, predicting the popularity of Skittles will likely have higher accuracy than predicting the popularity of Andes Mints; Skittles is in the dataset, and Andes Mints is not.\n",
        "\n",
        "You've built a model based on 50 candies using the dataset X_train and need to report how accurate the model is at predicting the popularity of the 50 candies the model was built on, and the 35 candies (X_test) it has never seen. You will use the mean absolute error, mae(), as the accuracy metric.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Using X_train and X_test as input data, create arrays of predictions using model.predict().\n",
        "Calculate model accuracy on both data the model has seen and data the model has not seen before.\n",
        "Use the print statements to print the seen and unseen data."
      ],
      "metadata": {
        "id": "ai38jsPRZhOZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsIHJFwsQ_1k"
      },
      "outputs": [],
      "source": [
        "# The model is fit using X_train and y_train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Create vectors of predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Train/Test Errors\n",
        "train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
        "test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
        "\n",
        "# Print the accuracy for seen and unseen data\n",
        "print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
        "print(\"Model error on unseen data: {0:.2f}.\".format(test_error))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set parameters and fit a model\n",
        "Predictive tasks fall into one of two categories: regression or classification. In the candy dataset, the outcome is a continuous variable describing how often the candy was chosen over another candy in a series of 1-on-1 match-ups. To predict this value (the win-percentage), you will use a regression model.\n",
        "\n",
        "In this exercise, you will specify a few parameters using a random forest regression model rfr.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Add a parameter to rfr so that the number of trees built is 100 and the maximum depth of these trees is 6.\n",
        "Make sure the model is reproducible by adding a random state of 1111.\n",
        "Use the .fit() method to train the random forest regression model with X_train as the input data and y_train as the response."
      ],
      "metadata": {
        "id": "h6c-p3EfdOvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of trees\n",
        "rfr.n_estimators = 100\n",
        "\n",
        "# Add a maximum depth\n",
        "rfr.max_depth = 6\n",
        "\n",
        "# Set the random state\n",
        "rfr.random_state = 1111\n",
        "\n",
        "# Fit the model\n",
        "rfr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "uSDYmn5EdPCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature importances\n",
        "Although some candy attributes, such as chocolate, may be extremely popular, it doesn't mean they will be important to model prediction. After a random forest model has been fit, you can review the model's attribute, .feature_importances_, to see which variables had the biggest impact. You can check how important each variable was in the model by looping over the feature importance array using enumerate().\n",
        "\n",
        "If you are unfamiliar with Python's enumerate() function, it can loop over a list while also creating an automatic counter.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Loop through the feature importance output of rfr.\n",
        "Print the column names of X_train and the importance score for that column."
      ],
      "metadata": {
        "id": "XrFvzprtd5Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model using X and y\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print how important each column is to the model\n",
        "for i, item in enumerate(rfr.feature_importances_):\n",
        "      # Use i and item to print out the feature importance of each column\n",
        "    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
      ],
      "metadata": {
        "id": "Dfw-VPSod5fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification predictions\n",
        "In model validation, it is often important to know more about the predictions than just the final classification. When predicting who will win a game, most people are also interested in how likely it is a team will win.\n",
        "```\n",
        "Probability\t| Prediction   |\tMeaning\n",
        "0 < .50     |\t     0\t   | Team Loses\n",
        ".50 +       |    \t 1\t   | Team Wins\n",
        "```\n",
        "In this exercise, you look at the methods, .predict() and .predict_proba() using the tic_tac_toe dataset. The first method will give a prediction of whether Player One will win the game, and the second method will provide the probability of Player One winning. Use rfc as the random forest classification model.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create two arrays of predictions. One for the classification values and one for the predicted probabilities.\n",
        "Use the .value_counts() method for a pandas Series to print the number of observations that were assigned to each class.\n",
        "Print the first observation of probability_predictions to see how the probabilities are structured."
      ],
      "metadata": {
        "id": "NGb1TZhagsdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the rfc model.\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create arrays of predictions\n",
        "classification_predictions = rfc.predict(X_test)\n",
        "probability_predictions = rfc.predict_proba(X_test)\n",
        "\n",
        "# Print out count of binary predictions\n",
        "print(pd.Series(classification_predictions).value_counts())\n",
        "\n",
        "# Print the first value from probability_predictions\n",
        "print('The first predicted probabilities are: {}'.format(probability_predictions[0]))"
      ],
      "metadata": {
        "id": "y71DRqTqhAsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reusing model parameters\n",
        "Replicating model performance is vital in model validation. Replication is also important when sharing models with co-workers, reusing models on new data or asking questions on a website such as Stack Overflow. You might use such a site to ask other coders about model errors, output, or performance. The best way to do this is to replicate your work by reusing model parameters.\n",
        "\n",
        "In this exercise, you use various methods to recall which parameters were used in a model.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Print out the characteristics of the model rfc by simply printing the model.\n",
        "Print just the random state of the model.\n",
        "Print the dictionary of model parameters."
      ],
      "metadata": {
        "id": "NvJEYscrh1y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Print the classification model\n",
        "print(rfc)\n",
        "\n",
        "# Print the classification model's random state parameter\n",
        "print('The random state is: {}'.format(rfc.random_state))\n",
        "\n",
        "# Print all parameters\n",
        "print('Printing the parameters dictionary: {}'.format(rfc.get_params()))"
      ],
      "metadata": {
        "id": "vRnQWGfmh2RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random forest classifier\n",
        "This exercise reviews the four modeling steps discussed throughout this chapter using a random forest classification model. You will:\n",
        "\n",
        "Create a random forest classification model.\n",
        "Fit the model using the tic_tac_toe dataset.\n",
        "Make predictions on whether Player One will win (1) or lose (0) the current game.\n",
        "Finally, you will evaluate the overall accuracy of the model.\n",
        "Let's get started!\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Create rfc using the scikit-learn implementation of random forest classifiers and set a random state of 1111."
      ],
      "metadata": {
        "id": "hkGI0KTciTZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)"
      ],
      "metadata": {
        "id": "u6be8sfLiTtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Fit rfc using X_train for the training data and y_train for the responses."
      ],
      "metadata": {
        "id": "Gz9mFYBsia31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Fit rfc using X_train and y_train\n",
        "rfc.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rk1-_6raibLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "4\n",
        "Predict the class values for X_test."
      ],
      "metadata": {
        "id": "525ZimaTihLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Fit rfc using X_train and y_train\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create predictions on X_test\n",
        "predictions = rfc.predict(X_test)\n",
        "print(predictions[0:5])"
      ],
      "metadata": {
        "id": "EL_sHMXKihfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "Use the method .score() to print an accuracy metric for X_test given the actual values y_test."
      ],
      "metadata": {
        "id": "-KaDrKtfixOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Fit rfc using X_train and y_train\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create predictions on X_test\n",
        "predictions = rfc.predict(X_test)\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Print model accuracy using score() and the testing data\n",
        "print(rfc.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "wTOe_sTyixg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create one holdout set\n",
        "Your boss has asked you to create a simple random forest model on the tic_tac_toe dataset. She doesn't want you to spend much time selecting parameters; rather she wants to know how well the model will perform on future data. For future Tic-Tac-Toe games, it would be nice to know if your model can predict which player will win.\n",
        "\n",
        "The dataset tic_tac_toe has been loaded for your use.\n",
        "\n",
        "Note that in Python, =\\ indicates the code was too long for one line and has been split across two lines.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create the X dataset by creating dummy variables for all of the categorical columns.\n",
        "Split X and y into train (X_train, y_train) and test (X_test, y_test) datasets.\n",
        "Split the datasets using 10% for testing"
      ],
      "metadata": {
        "id": "Mv9ix1WzkB4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables using pandas\n",
        "X = pd.get_dummies(tic_tac_toe.iloc[:,0:9])\n",
        "y = tic_tac_toe.iloc[:, 9]\n",
        "\n",
        "# Create training and testing datasets. Use 10% for the test set\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.1, random_state=1111)"
      ],
      "metadata": {
        "id": "K3lPHjzJkCNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create two holdout sets\n",
        "You recently created a simple random forest model to predict Tic-Tac-Toe game wins for your boss, and at her request, you did not do any parameter tuning. Unfortunately, the overall model accuracy was too low for her standards. This time around, she has asked you to focus on model performance.\n",
        "\n",
        "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset.\n",
        "\n",
        "The datasets X and y have been loaded for your use.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create temporary datasets and testing datasets (X_test, y_test). Use 20% of the overall data for the testing datasets.\n",
        "Using the temporary datasets (X_temp, y_temp), create training (X_train, y_train) and validation (X_val, y_val) datasets.\n",
        "Use 25% of the temporary data for the validation datasets."
      ],
      "metadata": {
        "id": "UIpGrMHXVpmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create temporary training and final testing datasets\n",
        "X_temp, X_test, y_temp, y_test  =\\\n",
        "    train_test_split(X, y, test_size=0.2, random_state=1111)\n",
        "\n",
        "# Create the final training and validation datasets\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
      ],
      "metadata": {
        "id": "E0pjP5J8Vp74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean absolute error\n",
        "Communicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy. For example, when predicting the number of wins for a basketball team, if you predict 42, and they end up with 40, you can easily explain that the error was two wins.\n",
        "\n",
        "In this exercise, you are interviewing for a new position and are provided with two arrays. y_test, the true number of wins for all 30 NBA teams in 2017 and predictions, which contains a prediction for each team. To test your understanding, you are asked to both manually calculate the MAE and use sklearn.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Manually calculate the MAE using n as the number of observations predicted.\n",
        "Calculate the MAE using sklearn.\n",
        "Print off both accuracy values using the print statements."
      ],
      "metadata": {
        "id": "dP6IQnhVX5BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Manually calculate the MAE\n",
        "n = len(predictions)\n",
        "mae_one = sum(abs(y_test - predictions)) / n\n",
        "print('With a manual calculation, the error is {}'.format(mae_one))\n",
        "\n",
        "# Use scikit-learn to calculate the MAE\n",
        "mae_two = mean_absolute_error(y_test, predictions)\n",
        "print('Using scikit-learn, the error is {}'.format(mae_two))"
      ],
      "metadata": {
        "id": "Si4xmqToX5VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean squared error\n",
        "Let's focus on the 2017 NBA predictions again. Every year, there are at least a couple of NBA teams that win way more games than expected. If you use the MAE, this accuracy metric does not reflect the bad predictions as much as if you use the MSE. Squaring the large errors from bad predictions will make the accuracy look worse.\n",
        "\n",
        "In this example, NBA executives want to better predict team wins. You will use the mean squared error to calculate the prediction error. The actual wins are loaded as y_test and the predictions as predictions.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Manually calculate the MSE.\n",
        "\n",
        "Calculate the MSE using sklearn.\n"
      ],
      "metadata": {
        "id": "iUwaEpUQYR4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n = len(predictions)\n",
        "# Finish the manual calculation of the MSE\n",
        "mse_one = sum((y_test - predictions)**2) / n\n",
        "print('With a manual calculation, the error is {}'.format(mse_one))\n",
        "\n",
        "# Use the scikit-learn function to calculate MSE\n",
        "mse_two = mean_squared_error(y_test, predictions)\n",
        "print('Using scikit-learn, the error is {}'.format(mse_two))"
      ],
      "metadata": {
        "id": "DhbND9g4YYFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance on data subsets\n",
        "In professional basketball, there are two conferences, the East and the West. Coaches and fans often only care about how teams in their own conference will do this year.\n",
        "\n",
        "You have been working on an NBA prediction model and would like to determine if the predictions were better for the East or West conference. You added a third array to your data called labels, which contains an \"E\" for the East teams, and a \"W\" for the West. y_test and predictions have again been loaded for your use.\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Create an array east_teams that can be used to filter labels to East conference teams."
      ],
      "metadata": {
        "id": "z5lAxxZBc3CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the East conference teams\n",
        "east_teams = labels == \"E\""
      ],
      "metadata": {
        "id": "i996fN-qc3aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "4\n",
        "Create the arrays true_east and preds_east by filtering the arrays y_test and predictions."
      ],
      "metadata": {
        "id": "ga8wa8YSeU_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the East conference teams\n",
        "east_teams = labels == \"E\"\n",
        "\n",
        "# Create arrays for the true and predicted values\n",
        "true_east = y_test[east_teams]\n",
        "preds_east = predictions[east_teams]"
      ],
      "metadata": {
        "id": "10-K-hzseWb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "4\n",
        "Use the print statements to print the MAE (using scikit-learn) for the East conference. The mean_absolute_error function has been loaded as mae."
      ],
      "metadata": {
        "id": "X9KOcwKVeaRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the East conference teams\n",
        "east_teams = labels == \"E\"\n",
        "\n",
        "# Create arrays for the true and predicted values\n",
        "true_east = y_test[east_teams]\n",
        "preds_east = predictions[east_teams]\n",
        "\n",
        "# Print the accuracy metrics\n",
        "print('The MAE for East teams is {}'.format(\n",
        "    mae(true_east, preds_east)))"
      ],
      "metadata": {
        "id": "hujvLXnpeb8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "The variable west_error contains the MAE for the West teams. Use the print statement to print out the Western conference MAE.\n"
      ],
      "metadata": {
        "id": "UzyxEDLvg9bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the East conference teams\n",
        "east_teams = labels == \"E\"\n",
        "\n",
        "# Create arrays for the true and predicted values\n",
        "true_east = y_test[east_teams]\n",
        "preds_east = predictions[east_teams]\n",
        "\n",
        "# Print the accuracy metrics\n",
        "print('The MAE for East teams is {}'.format(\n",
        "    mae(true_east, preds_east)))\n",
        "\n",
        "# Print the West accuracy\n",
        "print('The MAE for West conference is {}'.format(west_error))"
      ],
      "metadata": {
        "id": "6okAAAs7g9pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrices\n",
        "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.\n",
        "\n",
        "You have built a classification model to predict if a person has a broken arm based on an X-ray image. On the testing set, you have the following confusion matrix:\n",
        "```\n",
        "            | Prediction: 0    |\tPrediction: 1\n",
        "Actual: 0\t|   324 (TN)       |\t   15 (FP)\n",
        "Actual: 1\t|   123 (FN)\t   |    491 (TP)\n",
        "```\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Use the confusion matrix to calculate overall accuracy.\n",
        "Use the confusion matrix to calculate precision and recall.\n",
        "Use the three print statements to print each accuracy value."
      ],
      "metadata": {
        "id": "-SDTxwijihNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the accuracy\n",
        "accuracy = (324 + 491) / (953)\n",
        "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
        "\n",
        "# Calculate and print the precision\n",
        "precision = (491) / (491 + 15)\n",
        "print(\"The precision is {0: 0.2f}\".format(precision))\n",
        "\n",
        "# Calculate and print the recall\n",
        "recall = (491) / (491 + 123)\n",
        "print(\"The recall is {0: 0.2f}\".format(recall))"
      ],
      "metadata": {
        "id": "NUjDM5MiivVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrices, again\n",
        "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix. This exercise makes sure you understand the sklearn implementation of confusion matrices. Here, you have created a random forest model using the tic_tac_toe dataset rfc to predict outcomes of 0 (loss) or 1 (a win) for Player One.\n",
        "\n",
        "Note: If you read about confusion matrices on another website or for another programming language, the values might be reversed.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import sklearn's function for creating confusion matrices.\n",
        "Using the model rfc, create category predictions on the test set X_test.\n",
        "Create a confusion matrix using sklearn.\n",
        "Print the value from cm that represents the actual 1s that were predicted as 1s (true positives)."
      ],
      "metadata": {
        "id": "WC0DGl1yj2Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create predictions\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create and print the confusion matrix\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "print(cm)\n",
        "\n",
        "# Print the true positives (actual 1s that were predicted 1s)\n",
        "print(\"The number of true positives is: {}\".format(cm[1, 1]))"
      ],
      "metadata": {
        "id": "s9cKXcPuj2bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Precision vs. recall\n",
        "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.\n",
        "\n",
        "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!\n",
        "\n",
        "Use rfc, which is a random forest classification model built on the tic_tac_toe dataset.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the precision or the recall metric for sklearn. Only one method is correct for the given context.\n",
        "Calculate the precision or recall using y_test for the true values and test_predictions for the predictions.\n",
        "Print the final score based on your selected metric."
      ],
      "metadata": {
        "id": "5ncVX3NhkSz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create precision or recall score based on the metric you imported\n",
        "score = precision_score(y_test, test_predictions)\n",
        "\n",
        "# Print the final result\n",
        "print(\"The precision value is {0:.2f}\".format(score))"
      ],
      "metadata": {
        "id": "q2ltEmCXkTIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error due to under/over-fitting\n",
        "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting.\n",
        "\n",
        "A feature represents which columns of the data are used in a decision tree. The parameter max_features limits the number of features available.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Create a random forest model with 25 trees, a random state of 1111, and max_features of 2. Read the print statements."
      ],
      "metadata": {
        "id": "3NiOvXKalkJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=2)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies\n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "metadata": {
        "id": "K3fWxeF8lkdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Set max_features to 11 (the number of columns in the dataset). Read the print statements."
      ],
      "metadata": {
        "id": "21poArauluAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=11)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies\n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "metadata": {
        "id": "Ys9lq3vAlvS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "\n",
        "Set max_features equal to 4. Read the print statements."
      ],
      "metadata": {
        "id": "LmwfrV6vl5z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=4)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies\n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "metadata": {
        "id": "49zNTxpDl7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Am I underfitting?\n",
        "You are creating a random forest model to predict if you will win a future game of Tic-Tac-Toe. Using the tic_tac_toe dataset, you have created training and testing datasets, X_train, X_test, y_train, and y_test.\n",
        "\n",
        "You have decided to create a bunch of random forest models with varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting. You have created a for loop to test your model at the different number of trees.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "For each loop, predict values for both the X_train and X_test datasets.\n",
        "For each loop, append the accuracy_score() of the y_train dataset and the corresponding predictions to train_scores.\n",
        "For each loop, append the accuracy_score() of the y_test dataset and the corresponding predictions to test_scores.\n",
        "Print the training and testing scores using the print statements."
      ],
      "metadata": {
        "id": "Tpn5gJM7mqOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_scores, train_scores = [], []\n",
        "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
        "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    # Create predictions for the X_train and X_test datasets.\n",
        "    train_predictions = rfc.predict(X_train)\n",
        "    test_predictions = rfc.predict(X_test)\n",
        "    # Append the accuracy score for the test and train predictions.\n",
        "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
        "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
        "# Print the train and test scores.\n",
        "print(\"The training scores were: {}\".format(train_scores))\n",
        "print(\"The testing scores were: {}\".format(test_scores))"
      ],
      "metadata": {
        "id": "kYTQEo60mqjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}