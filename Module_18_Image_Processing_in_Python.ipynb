{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU7akqEcngoZ0S27ILdA3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_18_Image_Processing_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "PNgIEXty7w4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RGB to grayscale\n",
        "In this exercise you will load an image from scikit-image module data and make it grayscale, then compare both of them in the output.\n",
        "\n",
        "We have preloaded a function show_image(image, title='Image') that displays the image using Matplotlib. You can check more about its parameters using ?show_image() or help(show_image) in the console.\n",
        "\n",
        "Rocket\n",
        "Instructions\n",
        "100 XP\n",
        "Import the data and color modules from Scikit image. The first module provides example images, and the second, color transformation functions.\n",
        "Load the rocket image.\n",
        "Convert the RGB-3 rocket image to grayscale."
      ],
      "metadata": {
        "id": "awl8rSZo70DM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPNVHCGxiGkB"
      },
      "outputs": [],
      "source": [
        "# Import the modules from skimage\n",
        "from skimage import data, color\n",
        "\n",
        "# Load the rocket image\n",
        "rocket = data.rocket()\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_scaled_rocket = color.rgb2gray(rocket)\n",
        "\n",
        "# Show the original image\n",
        "show_image(rocket, 'Original RGB image')\n",
        "\n",
        "# Show the grayscale image\n",
        "show_image(gray_scaled_rocket, 'Grayscale image')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flipping out\n",
        "As a prank, someone has turned an image from a photo album of a trip to Seville upside-down and back-to-front! Now, we need to straighten the image, by flipping it.\n",
        "\n",
        "City of Seville upside-down\n",
        "Image loaded as flipped_seville.\n",
        "Using the NumPy methods learned in the course, flip the image horizontally and vertically. Then display the corrected image using the show_image() function.\n",
        "NumPy is already imported as np.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Flip the image vertically."
      ],
      "metadata": {
        "id": "UxqVXqXTTPrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flip the image vertically\n",
        "seville_vertical_flip = np.flipud(flipped_seville)"
      ],
      "metadata": {
        "id": "QojsJB1zTQJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Now, flip the vertically-flipped image horizontally."
      ],
      "metadata": {
        "id": "cg9xrM0GTWNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flip the image vertically\n",
        "seville_vertical_flip = np.flipud(flipped_seville)\n",
        "\n",
        "# Flip the previous image horizontally\n",
        "seville_horizontal_flip = np.fliplr(seville_vertical_flip)"
      ],
      "metadata": {
        "id": "eSxDoLj7TWW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Show the, now fixed, image.\n"
      ],
      "metadata": {
        "id": "AvGwL1dNTbru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flip the image vertically\n",
        "seville_vertical_flip = np.flipud(flipped_seville)\n",
        "\n",
        "# Flip the image horizontally\n",
        "seville_horizontal_flip = np.fliplr(seville_vertical_flip)\n",
        "\n",
        "# Show the resulting image\n",
        "show_image(seville_horizontal_flip, 'Seville')"
      ],
      "metadata": {
        "id": "ietk6I78TcCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histograms\n",
        "In this exercise, you will analyze the amount of red in the image. To do this, the histogram of the red channel will be computed for the image shown below:\n",
        "\n",
        "Woman smiling\n",
        "Image loaded as image.\n",
        "Extracting information from images is a fundamental part of image enhancement. This way you can balance the red and blue to make the image look colder or warmer.\n",
        "\n",
        "You will use hist() to display the 256 different intensities of the red color. And ravel() to make these color values an array of one flat dimension.\n",
        "\n",
        "Matplotlib is preloaded as plt and Numpy as np.\n",
        "\n",
        "Remember that if we want to obtain the green color of an image we would do the following:\n",
        "\n",
        "green = image[:, :, 1]\n",
        "Instructions\n",
        "100 XP\n",
        "Instructions\n",
        "100 XP\n",
        "Obtain the red channel using slicing.\n",
        "Plot the histogram and bins in a range of 256. Don't forget .ravel() for the color channel."
      ],
      "metadata": {
        "id": "sPQCoxscTlE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the red channel\n",
        "red_channel = image[:, :, 0]\n",
        "\n",
        "# Plot the red histogram with bins in a range of 256\n",
        "plt.hist(red_channel.ravel(), bins=256)\n",
        "\n",
        "# Set title and show\n",
        "plt.title('Red Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cXYTMwioTmCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply global thresholding\n",
        "In this exercise, you'll transform a photograph to binary so you can separate the foreground from the background.\n",
        "\n",
        "To do so, you need to import the required modules, load the image, obtain the optimal thresh value using threshold_otsu() and apply it to the image.\n",
        "\n",
        "You'll see the resulting binarized image when using the show_image() function, previously explained.\n",
        "\n",
        "Chess pieces\n",
        "Image loaded as chess_pieces_image.\n",
        "Remember we have to turn colored images to grayscale. For that we will use the rgb2gray() function learned in previous video. Which has already been imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the otsu threshold function.\n",
        "Turn the image to grayscale.\n",
        "Obtain the optimal threshold value of the image.\n",
        "Apply thresholding to the image."
      ],
      "metadata": {
        "id": "ZwkYnwa3UfD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the otsu threshold function\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# Make the image grayscale using rgb2gray\n",
        "chess_pieces_image_gray = rgb2gray(chess_pieces_image)\n",
        "\n",
        "# Obtain the optimal threshold value with otsu\n",
        "thresh = threshold_otsu(chess_pieces_image_gray)\n",
        "\n",
        "# Apply thresholding to the image\n",
        "binary = chess_pieces_image_gray > thresh\n",
        "\n",
        "# Show the image\n",
        "show_image(binary, 'Binary image')"
      ],
      "metadata": {
        "id": "svyL9CXJUfkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When the background isn't that obvious\n",
        "Sometimes, it isn't that obvious to identify the background. If the image background is relatively uniform, then you can use a global threshold value as we practiced before, using threshold_otsu(). However, if there's uneven background illumination, adaptive thresholding threshold_local() (a.k.a. local thresholding) may produce better results.\n",
        "\n",
        "In this exercise, you will compare both types of thresholding methods (global and local), to find the optimal way to obtain the binary image we need.\n",
        "\n",
        "Page with text\n",
        "Image loaded as page_image.\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "Import the otsu threshold function, obtain the optimal global thresh value of the image, and apply global thresholding."
      ],
      "metadata": {
        "id": "GEkcLTkrUrNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the otsu threshold function\n",
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "# Obtain the optimal otsu global thresh value\n",
        "global_thresh = threshold_otsu(page_image)\n",
        "\n",
        "# Obtain the binary image by applying global thresholding\n",
        "binary_global = page_image > global_thresh\n",
        "\n",
        "# Show the binary image obtained\n",
        "show_image(binary_global, 'Global thresholding')"
      ],
      "metadata": {
        "id": "ucnc9GEWUrm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "\n",
        "\n",
        "Import the local threshold function, set block size to 35, obtain the local thresh value, and apply local thresholding."
      ],
      "metadata": {
        "id": "76IbjNSLUwx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the local threshold function\n",
        "from skimage.filters import threshold_local\n",
        "\n",
        "# Set the block size to 35\n",
        "block_size = 35\n",
        "\n",
        "# Obtain the optimal local thresholding\n",
        "local_thresh = threshold_local(page_image, block_size, offset=10)\n",
        "\n",
        "# Obtain the binary image by applying local thresholding\n",
        "binary_local = page_image > local_thresh\n",
        "\n",
        "# Show the binary image\n",
        "show_image(binary_local, 'Local thresholding')"
      ],
      "metadata": {
        "id": "gAjgGOBYU04h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying other methods\n",
        "As we saw in the video, not being sure about what thresholding method to use isn't a problem. In fact, scikit-image provides us with a function to check multiple methods and see for ourselves what the best option is. It returns a figure comparing the outputs of different global thresholding methods.\n",
        "\n",
        "Forest fruits\n",
        "Image loaded as fruits_image.\n",
        "You will apply this function to this image, matplotlib.pyplot has been loaded as plt. Remember that you can use try_all_threshold() to try multiple global algorithms.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the try all function.\n",
        "Import the rgb to gray convertor function.\n",
        "Turn the fruits image to grayscale."
      ],
      "metadata": {
        "id": "4BtWvwpCU-cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the try all function\n",
        "from skimage.filters import try_all_threshold\n",
        "\n",
        "# Import the rgb to gray convertor function\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "# Turn the fruits_image to grayscale\n",
        "grayscale = rgb2gray(fruits_image)\n",
        "\n",
        "# Use the try all method on the resulting grayscale image\n",
        "fig, ax = try_all_threshold(grayscale, verbose=False)\n",
        "\n",
        "# Show the resulting plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jmaP2pYJU-wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply thresholding\n",
        "In this exercise, you will decide what type of thresholding is best used to binarize an image of knitting and craft tools. In doing so, you will be able to see the shapes of the objects, from paper hearts to scissors more clearly.\n",
        "\n",
        "Several tools for handcraft art\n",
        "Image loaded as tools_image.\n",
        "What type of thresholding would you use judging by the characteristics of the image? Is the background illumination and intensity even or uneven?\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the appropriate thresholding and rgb2gray() functions.\n",
        "Turn the image to grayscale.\n",
        "Obtain the optimal thresh.\n",
        "Obtain the binary image by applying thresholding."
      ],
      "metadata": {
        "id": "P2DMwvLqVIhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import threshold and gray convertor functions\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "# Turn the image grayscale\n",
        "gray_tools_image = rgb2gray(tools_image)\n",
        "\n",
        "# Obtain the optimal thresh\n",
        "thresh = threshold_otsu(gray_tools_image)\n",
        "\n",
        "# Obtain the binary image by applying thresholding\n",
        "binary_image = gray_tools_image > thresh\n",
        "\n",
        "# Show the resulting binary image\n",
        "show_image(binary_image, 'Binarized image')"
      ],
      "metadata": {
        "id": "MMxMbbrUVJEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edge detection\n",
        "In this exercise, you'll detect edges in an image by applying the Sobel filter.\n",
        "\n",
        "Soap pills of heart and rectangle shapes in blue background\n",
        "Image preloaded as soaps_image.\n",
        "Theshow_image() function has been already loaded for you.\n",
        "\n",
        "Let's see if it spots all the figures in the image.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the color module so you can convert the image to grayscale.\n",
        "Import the sobel() function from filters module.\n",
        "Make soaps_image grayscale using the appropriate method from the color module.\n",
        "Apply the sobel edge detection filter on the obtained grayscale image soaps_image_gray."
      ],
      "metadata": {
        "id": "yPrPRFzQVzls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the color module\n",
        "from skimage import color\n",
        "\n",
        "# Import the filters module and sobel function\n",
        "from skimage.filters import sobel\n",
        "\n",
        "# Make the image grayscale\n",
        "soaps_image_gray = color.rgb2gray(soaps_image)\n",
        "\n",
        "# Apply edge detection filter\n",
        "edge_sobel = sobel(soaps_image_gray)\n",
        "\n",
        "# Show original and resulting image to compare\n",
        "show_image(soaps_image, \"Original\")\n",
        "show_image(edge_sobel, \"Edges with Sobel\")"
      ],
      "metadata": {
        "id": "wYVkDIjSVz50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Blurring to reduce noise\n",
        "In this exercise you will reduce the sharpness of an image of a building taken during a London trip, through filtering.\n",
        "\n",
        "Building in Lodon\n",
        "Image loaded as building_image.\n",
        "Instructions\n",
        "100 XP\n",
        "Import the Gaussian filter.\n",
        "Apply the filter to the building_image, set the multichannel parameter to the correct value.\n",
        "Show the original building_image and resulting gaussian_image."
      ],
      "metadata": {
        "id": "qzhDpdQ3V80y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Gaussian filter\n",
        "from skimage.filters import gaussian\n",
        "\n",
        "# Apply filter\n",
        "gaussian_image = gaussian(building_image, multichannel=True)\n",
        "\n",
        "# Show original and resulting image to compare\n",
        "show_image(building_image, \"Original\")\n",
        "show_image(gaussian_image, \"Reduced sharpness Gaussian\")"
      ],
      "metadata": {
        "id": "ANTmojk4V9aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medical images\n",
        "You are trying to improve the tools of a hospital by pre-processing the X-ray images so that doctors have a higher chance of spotting relevant details. You'll test our code on a chest X-ray image from the National Institutes of Health Chest X-Ray Dataset\n",
        "\n",
        "X-ray chest image\n",
        "\n",
        "Image loaded as chest_xray_image.\n",
        "First, you'll check the histogram of the image and then apply standard histogram equalization to improve the contrast. Remember we obtain the histogram by using the hist() function from Matplotlib, which has been already imported as plt.\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Import the required Scikit-image module for contrast.\n"
      ],
      "metadata": {
        "id": "s6aWAqKUYEY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module\n",
        "from skimage import exposure"
      ],
      "metadata": {
        "id": "XW6-v6GeYEua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Show the histogram from the original x-ray image chest_xray_image, using the hist() function."
      ],
      "metadata": {
        "id": "_7tq8UAhYNdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module\n",
        "from skimage import exposure\n",
        "\n",
        "# Show original x-ray image and its histogram\n",
        "show_image(chest_xray_image, 'Original x-ray')\n",
        "\n",
        "plt.title('Histogram of image')\n",
        "plt.hist(chest_xray_image.ravel(), bins=256)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g4h5OUjWYOIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Use histogram equalization on chest_xray_image to obtain the improved image and load it as xray_image_eq."
      ],
      "metadata": {
        "id": "rvdwETgsYUWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module\n",
        "from skimage import exposure\n",
        "\n",
        "# Show original x-ray image and its histogram\n",
        "show_image(chest_xray_image, 'Original x-ray')\n",
        "\n",
        "plt.title('Histogram of image')\n",
        "plt.hist(chest_xray_image.ravel(), bins=256)\n",
        "plt.show()\n",
        "\n",
        "# Use histogram equalization to improve the contrast\n",
        "xray_image_eq =  exposure.equalize_hist(chest_xray_image)"
      ],
      "metadata": {
        "id": "MSJ-TswCYVHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Show the resulting improved image xray_image_eq"
      ],
      "metadata": {
        "id": "bwcpFPXhYdG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module\n",
        "from skimage import exposure\n",
        "\n",
        "# Show original x-ray image and its histogram\n",
        "show_image(chest_xray_image, 'Original x-ray')\n",
        "\n",
        "plt.title('Histogram of image')\n",
        "plt.hist(chest_xray_image.ravel(), bins=256)\n",
        "plt.show()\n",
        "\n",
        "# Use histogram equalization to improve the contrast\n",
        "xray_image_eq =  exposure.equalize_hist(chest_xray_image)\n",
        "\n",
        "# Show the resulting image\n",
        "show_image(xray_image_eq, 'Resulted image')"
      ],
      "metadata": {
        "id": "PCICvt1lYdZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aerial image\n",
        "In this exercise, we will improve the quality of an aerial image of a city. The image has low contrast and therefore we can not distinguish all the elements in it.\n",
        "\n",
        "Aerial image, airport taken from the air\n",
        "Image loaded as image_aerial.\n",
        "For this we will use the normal or standard technique of Histogram Equalization.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the required module from scikit-image.\n",
        "Use the histogram equalization function from the module previously imported.\n",
        "Show the resulting image."
      ],
      "metadata": {
        "id": "l9Mo5lIYYnkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module\n",
        "from skimage import exposure\n",
        "\n",
        "# Use histogram equalization to improve the contrast\n",
        "image_eq =  exposure.equalize_hist(image_aerial)\n",
        "\n",
        "# Show the original and resulting image\n",
        "show_image(image_aerial, 'Original')\n",
        "show_image(image_eq, 'Resulting image')"
      ],
      "metadata": {
        "id": "y1fq2v5ZYn4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's add some impact and contrast\n",
        "Have you ever wanted to enhance the contrast of your photos so that they appear more dramatic?\n",
        "\n",
        "In this exercise, you'll increase the contrast of a cup of coffee. Something you could share with your friends on social media. Don't forget to use #ImageProcessingDatacamp as hashtag!\n",
        "\n",
        "Even though this is not our Sunday morning coffee cup, you can still apply the same methods to any of our photos.\n",
        "\n",
        "Cup of coffee\n",
        "A function called show_image(), that displays an image using Matplotlib, has already been defined. It has the arguments image and title, with title being 'Original' by default.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the module that includes the Contrast Limited Adaptive Histogram Equalization (CLAHE) function.\n",
        "Obtain the image you'll work on, with a cup of coffee in it, from the module that holds all the images for testing purposes.\n",
        "From the previously imported module, call the function to apply the adaptive equalization method on the original image and set the clip limit to 0.03."
      ],
      "metadata": {
        "id": "0dW8P9toYx9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from skimage import data, exposure\n",
        "\n",
        "# Load the image\n",
        "original_image = data.coffee()\n",
        "\n",
        "# Apply the adaptive equalization on the original image\n",
        "adapthist_eq_image = exposure.equalize_adapthist(original_image, clip_limit=0.03)\n",
        "\n",
        "# Compare the original image to the equalized\n",
        "show_image(original_image)\n",
        "show_image(adapthist_eq_image, '#ImageProcessingDatacamp')"
      ],
      "metadata": {
        "id": "RoD6-ijCYyUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aliasing, rotating and rescaling\n",
        "Let's look at the impact of aliasing on images.\n",
        "\n",
        "Remember that aliasing is an effect that causes different signals, in this case pixels, to become indistinguishable or distorted.\n",
        "\n",
        "You'll make this cat image upright by rotating it 90 degrees and then rescaling it two times. Once with the anti aliasing filter applied before rescaling and a second time without it, so you can compare them.\n",
        "\n",
        "Little cute cat\n",
        "Image preloaded as image_cat.\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Import the module and the rotating and rescaling functions."
      ],
      "metadata": {
        "id": "maP6etYuZgKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and the rotate and rescale functions\n",
        "from skimage.transform import rotate, rescale"
      ],
      "metadata": {
        "id": "squYXhqzZghk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Rotate the image 90 degrees clockwise."
      ],
      "metadata": {
        "id": "P7sheXu5Zl9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and the rotate and rescale functions\n",
        "from skimage.transform import rotate, rescale\n",
        "\n",
        "# Rotate the image 90 degrees clockwise\n",
        "rotated_cat_image = rotate(image_cat, -90)"
      ],
      "metadata": {
        "id": "r2CAZA80ZmHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Rescale the cat_image to be 4 times smaller and apply the anti aliasing filter. Set whether or not the image should be treated as multichannel (colored)."
      ],
      "metadata": {
        "id": "aOhW6o5FZqJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and the rotate and rescale functions\n",
        "from skimage.transform import rotate, rescale\n",
        "\n",
        "# Rotate the image 90 degrees clockwise\n",
        "rotated_cat_image = rotate(image_cat, -90)\n",
        "\n",
        "# Rescale with anti aliasing\n",
        "rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True)"
      ],
      "metadata": {
        "id": "3hRAdiz3ZqnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Rescale the rotated_cat_image to be 4 times smaller without applying an anti aliasing filter."
      ],
      "metadata": {
        "id": "gR9-x9YmZvbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and the rotate and rescale functions\n",
        "from skimage.transform import rotate, rescale\n",
        "\n",
        "# Rotate the image 90 degrees clockwise\n",
        "rotated_cat_image = rotate(image_cat, -90)\n",
        "\n",
        "# Rescale with anti aliasing\n",
        "rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True)\n",
        "\n",
        "# Rescale without anti aliasing\n",
        "rescaled_without_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=False, multichannel=True)\n",
        "\n",
        "# Show the resulting images\n",
        "show_image(rescaled_with_aa, \"Transformed with anti aliasing\")\n",
        "show_image(rescaled_without_aa, \"Transformed without anti aliasing\")"
      ],
      "metadata": {
        "id": "rg21gnplZwyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enlarging images\n",
        "Have you ever tried resizing an image to make it larger? This usually results in loss of quality, with the enlarged image looking blurry.\n",
        "\n",
        "The good news is that the algorithm used by scikit-image works very well for enlarging images up to a certain point.\n",
        "\n",
        "In this exercise you'll enlarge an image three times!!\n",
        "\n",
        "You'll do this by rescaling the image of a rocket, that will be loaded from the data module.\n",
        "\n",
        "Rocket\n",
        "Instructions\n",
        "100 XP\n",
        "Import the module and function needed to enlarge images, you'll do this by rescaling.\n",
        "Import the data module.\n",
        "Load the rocket() image from data.\n",
        "Enlarge the rocket_image so it is 3 times bigger, with the anti aliasing filter applied. Make sure to set multichannel to True or you risk your session timing out!"
      ],
      "metadata": {
        "id": "G48Kv1TfZ90W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and function to enlarge images\n",
        "from skimage.transform import rescale\n",
        "\n",
        "# Import the data module\n",
        "from skimage import data\n",
        "\n",
        "# Load the image from data\n",
        "rocket_image = data.rocket()\n",
        "\n",
        "# Enlarge the image so it is 3 times bigger\n",
        "enlarged_rocket_image = rescale(rocket_image, 3, anti_aliasing=True, multichannel=True)\n",
        "\n",
        "# Show original and resulting image\n",
        "show_image(rocket_image)\n",
        "show_image(enlarged_rocket_image, \"3 times enlarged image\")"
      ],
      "metadata": {
        "id": "GQf4anXrZ-N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proportionally resizing\n",
        "We want to downscale the images of a veterinary blog website so all of them have the same compressed size.\n",
        "\n",
        "It's important that you do this proportionally, meaning that these are not distorted.\n",
        "\n",
        "First, you'll try it out for one image so you know what code to test later in the rest of the pictures.\n",
        "\n",
        "\n",
        "The image preloaded as dogs_banner.\n",
        "Remember that by looking at the shape of the image, you can know its width and height.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the module and function to resize.\n",
        "Set the proportional height and width so it is half the image's height size.\n",
        "Resize using the calculated proportional height and width."
      ],
      "metadata": {
        "id": "RH51IvMOaIZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and function\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Set proportional height and width so it is half its size\n",
        "height = int(dogs_banner.shape[0] / 2.0)\n",
        "width = int(dogs_banner.shape[1] / 2.0)\n",
        "\n",
        "# Resize using the calculated proportional height and width\n",
        "image_resized = resize(dogs_banner, (height, width),\n",
        "                       anti_aliasing=True)\n",
        "\n",
        "# Show the original and resized image\n",
        "show_image(dogs_banner, 'Original')\n",
        "show_image(image_resized, 'Resized image')"
      ],
      "metadata": {
        "id": "VJIqXPqCaIru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten letters\n",
        "A very interesting use of computer vision in real-life solutions is performing Optical Character Recognition (OCR) to distinguish printed or handwritten text characters inside digital images of physical documents.\n",
        "\n",
        "Let's try to improve the definition of this handwritten letter so that it's easier to classify.\n",
        "\n",
        "\n",
        "As we can see it's the letter R, already binary, with some noise in it. It's already loaded as upper_r_image.\n",
        "\n",
        "Apply the morphological operation that will discard the pixels near the letter boundaries.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Instructions\n",
        "100 XP\n",
        "Import the module from scikit-image.\n",
        "Apply the morphological operation for eroding away the boundaries of regions of foreground pixels."
      ],
      "metadata": {
        "id": "w2hM2zQSa3uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the morphology module\n",
        "from skimage import morphology\n",
        "\n",
        "# Obtain the eroded shape\n",
        "eroded_image_shape = morphology.binary_erosion(upper_r_image)\n",
        "\n",
        "# See results\n",
        "show_image(upper_r_image, 'Original')\n",
        "show_image(eroded_image_shape, 'Eroded image')"
      ],
      "metadata": {
        "id": "ZDfFWJnXa4B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving thresholded image\n",
        "In this exercise, we'll try to reduce the noise of a thresholded image using the dilation morphological operation.\n",
        "\n",
        "World map\n",
        "Image already loaded as world_image.\n",
        "This operation, in a way, expands the objects in the image.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the module.\n",
        "Obtain the binarized and dilated image, from the original image world_image."
      ],
      "metadata": {
        "id": "uJsBEfcJbDwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module\n",
        "from skimage import morphology\n",
        "\n",
        "# Obtain the dilated image\n",
        "dilated_image = morphology.binary_dilation(world_image)\n",
        "\n",
        "# See results\n",
        "show_image(world_image, 'Original')\n",
        "show_image(dilated_image, 'Dilated image')"
      ],
      "metadata": {
        "id": "7pWRUE6ZbEF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's restore a damaged image\n",
        "In this exercise, we'll restore an image that has missing parts in it, using the inpaint_biharmonic() function.\n",
        "\n",
        "Small cute puppy\n",
        "Loaded as defect_image.\n",
        "We'll work on an image from the data module, obtained by data.astronaut(). Some of the pixels have been replaced with 0s using a binary mask, on purpose, to simulate a damaged image. Replacing pixels with 0s turns them totally black. The defective image is saved as an array called defect_image.\n",
        "\n",
        "The mask is a black and white image with patches that have the position of the image bits that have been corrupted. We can apply the restoration function on these areas. This mask is preloaded as mask.\n",
        "\n",
        "Remember that inpainting is the process of reconstructing lost or deteriorated parts of images and videos.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Import the inpaint function in the restoration module in scikit-image (skimage)."
      ],
      "metadata": {
        "id": "9Odk_lIwcmY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module from restoration\n",
        "from skimage.restoration import inpaint"
      ],
      "metadata": {
        "id": "vupGPr2icmt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Show the defective image using show_image()."
      ],
      "metadata": {
        "id": "lYGA_VovctvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module from restoration\n",
        "from skimage.restoration import inpaint\n",
        "\n",
        "# Show the defective image\n",
        "show_image(defect_image, 'Image to restore')"
      ],
      "metadata": {
        "id": "QNEuCPQ2cuHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "35 XP\n",
        "3\n",
        "Call the correct function from inpaint. Use the corrupted image as the first parameter, then the mask and multichannel boolean."
      ],
      "metadata": {
        "id": "FXbwz4uSc4yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module from restoration\n",
        "from skimage.restoration import inpaint\n",
        "\n",
        "# Show the defective image\n",
        "show_image(defect_image, 'Image to restore')\n",
        "\n",
        "# Apply the restoration function to the image using the mask\n",
        "restored_image = inpaint.inpaint_biharmonic(defect_image, mask, multichannel=True)\n",
        "show_image(restored_image)"
      ],
      "metadata": {
        "id": "rT-3ZroHc7mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing logos\n",
        "As we saw in the video, another use of image restoration is removing objects from an scene. In this exercise, we'll remove the Datacamp logo from an image.\n",
        "\n",
        "Landscape with small datacamp logo\n",
        "Image loaded as image_with_logo.\n",
        "You will create and set the mask to be able to erase the logo by inpainting this area.\n",
        "\n",
        "Remember that when you want to remove an object from an image you can either manually delineate that object or run some image analysis algorithm to find it.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Initialize a mask with the same shape as the image, using np.zeros().\n",
        "In the mask, set the region that will be inpainted to 1 .\n",
        "Apply inpainting to image_with_logo using the mask."
      ],
      "metadata": {
        "id": "VGeDvyQCdHXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the mask\n",
        "mask = np.zeros(image_with_logo.shape[:-1])\n",
        "\n",
        "# Set the pixels where the logo is to 1\n",
        "mask[210:290, 360:425] = 1\n",
        "\n",
        "# Apply inpainting to remove the logo\n",
        "image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo,\n",
        "                                                mask,\n",
        "                                                multichannel=True)\n",
        "\n",
        "# Show the original and logo removed images\n",
        "show_image(image_with_logo, 'Image with logo')\n",
        "show_image(image_logo_removed, 'Image with logo removed')"
      ],
      "metadata": {
        "id": "aylBwOrLdHpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's make some noise!\n",
        "In this exercise, we'll practice adding noise to a fruit image.\n",
        "\n",
        "Various fruits\n",
        "Image preloaded as fruit_image.\n",
        "Instructions\n",
        "100 XP\n",
        "Import the util module and the random noise function.\n",
        "Add noise to the image.\n",
        "Show the original and resulting image."
      ],
      "metadata": {
        "id": "p3ish7CdtZuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and function\n",
        "from skimage.util import random_noise\n",
        "\n",
        "# Add noise to the image\n",
        "noisy_image = random_noise(fruit_image)\n",
        "\n",
        "# Show original and resulting image\n",
        "show_image(fruit_image, 'Original')\n",
        "show_image(noisy_image, 'Noisy image')"
      ],
      "metadata": {
        "id": "7EUkEK0DtaDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing noise\n",
        "We have a noisy image that we want to improve by removing the noise in it.\n",
        "\n",
        "Small cute puppy\n",
        "Preloaded as noisy_image.\n",
        "Use total variation filter denoising to accomplish this.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the denoise_tv_chambolle function from its module.\n",
        "Apply total variation filter denoising.\n",
        "Show the original noisy and the resulting denoised image."
      ],
      "metadata": {
        "id": "04DnVfIwt6Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module and function\n",
        "from skimage.restoration import denoise_tv_chambolle\n",
        "\n",
        "# Apply total variation filter denoising\n",
        "denoised_image = denoise_tv_chambolle(noisy_image,\n",
        "                                      multichannel=True)\n",
        "\n",
        "# Show the noisy and denoised images\n",
        "show_image(noisy_image, 'Noisy')\n",
        "show_image(denoised_image, 'Denoised image')"
      ],
      "metadata": {
        "id": "qDaGW5Sst6h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing noise while preserving edges\n",
        "In this exercise, you will reduce the noise in this landscape picture.\n",
        "\n",
        "Landscape of a river\n",
        "Preloaded as landscape_image.\n",
        "Since we prefer to preserve the edges in the image, we'll use the bilateral denoising filter.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the denoise_bilateral function from its module.\n",
        "Apply bilateral filter denoising.\n",
        "Show the original noisy and the resulting denoised image.\n"
      ],
      "metadata": {
        "id": "ChkMyp8AuIJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import bilateral denoising function\n",
        "from skimage.restoration import denoise_bilateral\n",
        "\n",
        "# Apply bilateral filter denoising\n",
        "denoised_image = denoise_bilateral(landscape_image,\n",
        "                                   multichannel=True)\n",
        "\n",
        "# Show original and resulting images\n",
        "show_image(landscape_image, 'Noisy image')\n",
        "show_image(denoised_image, 'Denoised image')"
      ],
      "metadata": {
        "id": "4x4WpPPpuIdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Superpixel segmentation\n",
        "In this exercise, you will apply unsupervised segmentation to the same image, before it's passed to a face detection machine learning model.\n",
        "\n",
        "So you will reduce this image from 265 x 191 = 50,6115 pixels down to 400 regions.\n",
        "\n",
        "Young woman\n",
        "Already preloaded as face_image.\n",
        "The show_image() function has been preloaded for you as well.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the slic() function from the segmentation module.\n",
        "Import the label2rgb() function from the color module.\n",
        "Obtain the segmentation with 400 regions using slic().\n",
        "Put segments on top of original image to compare with label2rgb()."
      ],
      "metadata": {
        "id": "gxLGAZj6vH33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the slic function from segmentation module\n",
        "from skimage.segmentation import slic\n",
        "\n",
        "# Import the label2rgb function from color module\n",
        "from skimage.color import label2rgb\n",
        "\n",
        "# Obtain the segmentation with 400 regions\n",
        "segments = slic(face_image, n_segments= 400)\n",
        "\n",
        "# Put segments on top of original image to compare\n",
        "segmented_image = label2rgb(segments, face_image, kind='avg')\n",
        "\n",
        "# Show the segmented image\n",
        "show_image(segmented_image, \"Segmented image, 400 superpixels\")"
      ],
      "metadata": {
        "id": "-gHJvehsvPmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contouring shapes\n",
        "In this exercise we'll find the contour of a horse.\n",
        "\n",
        "For that we will make use of a binarized image provided by scikit-image in its data module. Binarized images are easier to process when finding contours with this algorithm. Remember that contour finding only supports 2D image arrays.\n",
        "\n",
        "Once the contour is detected, we will display it together with the original image. That way we can check if our analysis was correct!\n",
        "\n",
        "show_image_contour(image, contours) is a preloaded function that displays the image with all contours found using Matplotlib.\n",
        "\n",
        "Shape of a horse in black and white\n",
        "Remember you can use the find_contours() function from the measure module, by passing the thresholded image and a constant value.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Instructions\n",
        "100 XP\n",
        "Import the data and the module needed for contouring detection.\n",
        "Obtain the horse image shown in the context area.\n",
        "Find the contours of the horse image using a constant level value of 0.8."
      ],
      "metadata": {
        "id": "rUvHMC_AwCO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the modules\n",
        "from skimage import measure, data\n",
        "\n",
        "# Obtain the horse image\n",
        "horse_image = data.horse()\n",
        "\n",
        "# Find the contours with a constant level value of 0.8\n",
        "contours = measure.find_contours(horse_image, 0.8)\n",
        "\n",
        "# Shows the image with contours found\n",
        "show_image_contour(horse_image, contours)"
      ],
      "metadata": {
        "id": "IGPepkdwwCg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find contours of an image that is not binary\n",
        "Let's work a bit more on how to prepare an image to be able to find its contours and extract information from it.\n",
        "\n",
        "We'll process an image of two purple dice loaded as image_dice and determine what number was rolled for each dice.\n",
        "\n",
        "Purple dice\n",
        "In this case, the image is not grayscale or binary yet. This means we need to perform some image pre-processing steps before looking for the contours. First, we'll transform the image to a 2D array grayscale image and next apply thresholding. Finally, the contours are displayed together with the original image.\n",
        "\n",
        "color, measure and filters modules are already imported so you can use the functions to find contours and apply thresholding.\n",
        "\n",
        "We also import the io module to load the image_dice from local memory, using imread. Read more here (https://scikit-image.org/docs/dev/api/skimage.io.html).\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Transform the image to grayscale using rgb2gray()."
      ],
      "metadata": {
        "id": "BYp1ryKHwMdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the image grayscale\n",
        "image_dice = color.rgb2gray(image_dice)"
      ],
      "metadata": {
        "id": "hbCYmieqwNAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Obtain the optimal threshold value for the image and set it as thresh."
      ],
      "metadata": {
        "id": "FAtb3v8jwVCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the image grayscale\n",
        "image_dice = color.rgb2gray(image_dice)\n",
        "\n",
        "# Obtain the optimal thresh value\n",
        "thresh = filters.threshold_otsu(image_dice)"
      ],
      "metadata": {
        "id": "hL2--SxpwV1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Apply thresholding to the image once you have the optimal threshold value thresh, using the corresponding operator."
      ],
      "metadata": {
        "id": "LulUCK-WwbtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the image grayscale\n",
        "image_dice = color.rgb2gray(image_dice)\n",
        "\n",
        "# Obtain the optimal thresh value\n",
        "thresh = filters.threshold_otsu(image_dice)\n",
        "\n",
        "# Apply thresholding\n",
        "binary = image_dice > thresh"
      ],
      "metadata": {
        "id": "1Je7u9A2wb2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Apply the corresponding function to obtain the contours and use a value level of 0.8."
      ],
      "metadata": {
        "id": "t13FSW7owf1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the image grayscale\n",
        "image_dice = color.rgb2gray(image_dice)\n",
        "\n",
        "# Obtain the optimal thresh value\n",
        "thresh = filters.threshold_otsu(image_dice)\n",
        "\n",
        "# Apply thresholding\n",
        "binary = image_dice > thresh\n",
        "\n",
        "# Find contours at a constant value of 0.8\n",
        "contours = measure.find_contours(binary, 0.8)\n",
        "\n",
        "# Show the image\n",
        "show_image_contour(image_dice, contours)"
      ],
      "metadata": {
        "id": "qeTi_GCYwgnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count the dots in a dice's image\n",
        "Now we have found the contours, we can extract information from it.\n",
        "\n",
        "In the previous exercise, we prepared a purple dices image to find its contours:\n",
        "\n",
        "3 images showing the steps to find contours\n",
        "\n",
        "This time we'll determine what number was rolled for the dice, by counting the dots in the image.\n",
        "\n",
        "The contours found in the previous exercise are preloaded as contours.\n",
        "\n",
        "Create a list with all contour's shapes as shape_contours. You can see all the contours shapes by calling shape_contours in the console, once you have created it.\n",
        "\n",
        "Check that most of the contours aren't bigger in size than 50. If you count them, they are the exact number of dots in the image.\n",
        "\n",
        "show_image_contour(image, contours) is a preloaded function that displays the image with all contours found using Matplotlib.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Make shape_contours be a list with all contour shapes of contours.\n",
        "Set max_dots_shape to 50.\n",
        "Set the shape condition of the contours to be the maximum shape size of the dots max_dots_shape.\n",
        "Print the dice's number."
      ],
      "metadata": {
        "id": "8fbp5D91wl1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list with the shape of each contour\n",
        "shape_contours = [cnt.shape[0] for cnt in contours]\n",
        "\n",
        "# Set 50 as the maximum size of the dots shape\n",
        "max_dots_shape = 50\n",
        "\n",
        "# Count dots in contours excluding bigger than dots size\n",
        "dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]\n",
        "\n",
        "# Shows all contours found\n",
        "show_image_contour(binary, contours)\n",
        "\n",
        "# Print the dice's number\n",
        "print(\"Dice's dots number: {}. \".format(len(dots_contours)))"
      ],
      "metadata": {
        "id": "_4B-dvj_wmDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edges\n",
        "In this exercise you will identify the shapes in a grapefruit image by detecting the edges, using the Canny algorithm.\n",
        "\n",
        "Grapefruits\n",
        "Image preloaded as grapefruit.\n",
        "The color module has already been preloaded for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the canny edge detector from the feature module.\n",
        "Convert the image to grayscale, using the method from the color module used in previous chapters.\n",
        "Apply the canny edge detector to the grapefruit image."
      ],
      "metadata": {
        "id": "CH83mDP16siu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the canny edge detector\n",
        "from skimage.feature import canny\n",
        "\n",
        "# Convert image to grayscale\n",
        "grapefruit = color.rgb2gray(grapefruit)\n",
        "\n",
        "# Apply canny edge detector\n",
        "canny_edges = canny(grapefruit)\n",
        "\n",
        "# Show resulting image\n",
        "show_image(canny_edges, \"Edges with Canny\")"
      ],
      "metadata": {
        "id": "JDQ239-B6s9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Less edgy\n",
        "Let's now try to spot just the outer shape of the grapefruits, the circles. You can do this by applying a more intense Gaussian filter to first make the image smoother. This can be achieved by specifying a bigger sigma in the canny function.\n",
        "\n",
        "In this exercise, you'll experiment with sigma values of the canny() function.\n",
        "\n",
        "Grapefruits\n",
        "Image preloaded as grapefruit.\n",
        "The show_image has already been preloaded.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "Apply the canny edge detector to the grapefruit image with a sigma of 1.8."
      ],
      "metadata": {
        "id": "eWNQ_umE64J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply canny edge detector with a sigma of 1.8\n",
        "canny_edges = canny(grapefruit, sigma=1.8)"
      ],
      "metadata": {
        "id": "NqnJKDtJ6448"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Apply the canny edge detector to the grapefruit image with a sigma of 2.2."
      ],
      "metadata": {
        "id": "g3_dB2fY68-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply canny edge detector with a sigma of 1.8\n",
        "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
        "\n",
        "# Apply canny edge detector with a sigma of 2.2\n",
        "edges_2_2 = canny(grapefruit, sigma=2.2)"
      ],
      "metadata": {
        "id": "oS9dNLT6696h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "\n",
        "Show the resulting images."
      ],
      "metadata": {
        "id": "GQUZ590x7DAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply canny edge detector with a sigma of 1.8\n",
        "edges_1_8 = canny(grapefruit, sigma=1.8)\n",
        "\n",
        "# Apply canny edge detector with a sigma of 2.2\n",
        "edges_2_2 = canny(grapefruit, sigma=2.2)\n",
        "\n",
        "# Show resulting images\n",
        "show_image(edges_1_8, \"Sigma of 1.8\")\n",
        "show_image(edges_2_2, \"Sigma of 2.2\")"
      ],
      "metadata": {
        "id": "2O1FzG5y7D6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perspective\n",
        "In this exercise, you will detect the corners of a building using the Harris corner detector. The threshold_rel parameter will specify the minimum intensity of peaks.\n",
        "\n",
        "Building from a bottom perspective\n",
        "Image preloaded as building_image.\n",
        "The functions show_image() and show_image_with_corners() have already been preloaded for you. As well as the color module for converting images to grayscale.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the corner_harris() function from the feature module.\n",
        "Convert the building_image to grayscale.\n",
        "Apply the harris detector to obtain the measure response image with the possible corners.\n",
        "Find the peaks of the corners."
      ],
      "metadata": {
        "id": "ttB76LTN7sUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the corner detector related functions and module\n",
        "from skimage.feature import corner_harris, corner_peaks\n",
        "\n",
        "# Convert image from RGB-3 to grayscale\n",
        "building_image_gray = color.rgb2gray(building_image)\n",
        "\n",
        "# Apply the detector  to measure the possible corners\n",
        "measure_image = corner_harris(building_image_gray)\n",
        "\n",
        "# Find the peaks of the corners\n",
        "coords = corner_peaks(measure_image, min_distance=20, threshold_rel=0.02)\n",
        "\n",
        "# Show original and resulting image with corners detected\n",
        "show_image(building_image, \"Original\")\n",
        "show_image_with_corners(building_image, coords)"
      ],
      "metadata": {
        "id": "lG9CY2rU7snM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Less corners\n",
        "In this exercise, you will test what happens when you set the minimum distance between corner peaks to be a higher number. Remember you do this with the min_distance attribute parameter of the corner_peaks() function. The threshold_rel parameter will specify the minimum intensity of peaks.\n",
        "\n",
        "Building from a bottom perspective\n",
        "Image preloaded as building_image.\n",
        "The functions show_image(), show_image_with_corners() and required packages have already been preloaded for you. As well as all the previous code for finding the corners. The Harris measure response image obtained with corner_harris() is preloaded as measure_image.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "Find the peaks of the corners with a minimum distance of 10 pixels."
      ],
      "metadata": {
        "id": "8VsSgmUD74a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the peaks with a min distance of 10 pixels\n",
        "coords_w_min_10 = corner_peaks(measure_image, min_distance=10, threshold_rel=0.02)\n",
        "print(\"With a min_distance set to 10, we detect a total\", len(coords_w_min_10), \"corners in the image.\")"
      ],
      "metadata": {
        "id": "UxB0-JdR74ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "\n",
        "Find the peaks of the corners with a minimum distance of 60 pixels."
      ],
      "metadata": {
        "id": "YZPQNscx79GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the peaks with a min distance of 10 pixels\n",
        "coords_w_min_10 = corner_peaks(measure_image, min_distance=10, threshold_rel=0.02)\n",
        "print(\"With a min_distance set to 10, we detect a total\", len(coords_w_min_10), \"corners in the image.\")\n",
        "\n",
        "# Find the peaks with a min distance of 60 pixels\n",
        "coords_w_min_60 = corner_peaks(measure_image, min_distance=60, threshold_rel=0.02)\n",
        "print(\"With a min_distance set to 60, we detect a total\", len(coords_w_min_60), \"corners in the image.\")"
      ],
      "metadata": {
        "id": "WLwPK-ky79_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "\n",
        "\n",
        "Show original and resulting image with corners detected."
      ],
      "metadata": {
        "id": "tocX08uj8Bnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the peaks with a min distance of 10 pixels\n",
        "coords_w_min_10 = corner_peaks(measure_image, min_distance=10, threshold_rel=0.02)\n",
        "print(\"With a min_distance set to 10, we detect a total\", len(coords_w_min_10), \"corners in the image.\")\n",
        "\n",
        "# Find the peaks with a min distance of 60 pixels\n",
        "coords_w_min_60 = corner_peaks(measure_image, min_distance=60, threshold_rel=0.02)\n",
        "print(\"With a min_distance set to 60, we detect a total\", len(coords_w_min_60), \"corners in the image.\")\n",
        "\n",
        "show_image_with_corners(building_image, coords_w_min_10, \"Corners detected with 10 px of min_distance\")\n",
        "show_image_with_corners(building_image, coords_w_min_60, \"Corners detected with 60 px of min_distance\")"
      ],
      "metadata": {
        "id": "7jc04QCI8DHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is someone there?\n",
        "In this exercise, you will check whether or not there is a person present in an image taken at night.\n",
        "\n",
        "LAndscape of starry night with a young man in the left bottom corner\n",
        "Image preloaded as night_image.\n",
        "The Cascade of classifiers class from feature module has been already imported. The same is true for the show_detected_face() function, that is used to display the face marked in the image and crop so it can be shown separately.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Load the trained file from the data module.\n",
        "Initialize the detector cascade with the trained file.\n",
        "Detect the faces in the image, setting the minimum size of the searching window to 10 pixels and 200 pixels for the maximum."
      ],
      "metadata": {
        "id": "EviWNjAz8tg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained file from data\n",
        "trained_file = data.lbp_frontal_face_cascade_filename()\n",
        "\n",
        "# Initialize the detector cascade\n",
        "detector = Cascade(trained_file)\n",
        "\n",
        "# Detect faces with min and max size of searching window\n",
        "detected = detector.detect_multi_scale(img = night_image,\n",
        "                                       scale_factor=1.2,\n",
        "                                       step_ratio=1,\n",
        "                                       min_size=(10, 10),\n",
        "                                       max_size=(200, 200))\n",
        "\n",
        "# Show the detected faces\n",
        "show_detected_face(night_image, detected)"
      ],
      "metadata": {
        "id": "FiYVcsCT8t3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple faces\n",
        "In this exercise, you will detect multiple faces in an image and show them individually. Think of this as a way to create a dataset of your own friends' faces!\n",
        "\n",
        "A group of 7 friends\n",
        "Image preloaded as friends_image.\n",
        "The Cascade of classifiers class from feature module has already been imported, as well as the show_detected_face() function which is used to display the face marked in the image and crop it so it can be shown separately.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Load the trained file .lbp_frontal_face_cascade_filename(). from the data module.\n",
        "Initialize the detector cascade with trained file.\n",
        "Detect the faces in the image, setting a scale_factor of 1.2 and step_ratio of 1.\n"
      ],
      "metadata": {
        "id": "jyDSfC-V8467"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained file from data\n",
        "trained_file = data.lbp_frontal_face_cascade_filename()\n",
        "\n",
        "# Initialize the detector cascade\n",
        "detector = Cascade(trained_file)\n",
        "\n",
        "# Detect faces with scale factor to 1.2 and step ratio to 1\n",
        "detected = detector.detect_multi_scale(img=friends_image,\n",
        "                                       scale_factor=1.2,\n",
        "                                       step_ratio=1,\n",
        "                                       min_size=(10, 10),\n",
        "                                       max_size=(200, 200))\n",
        "# Show the detected faces\n",
        "show_detected_face(friends_image, detected)"
      ],
      "metadata": {
        "id": "jHTsSx5385J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation and face detection\n",
        "Previously, you learned how to make processes more computationally efficient with unsupervised superpixel segmentation. In this exercise, you'll do just that!\n",
        "\n",
        "Using the slic() function for segmentation, pre-process the image before passing it to the face detector.\n",
        "\n",
        "Young woman selfie\n",
        "Image preloaded as profile_image.\n",
        "The Cascade class, the slic() function from segmentation module, and the show_detected_face() function for visualization have already been imported. The detector is already initialized and ready to use as detector.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Apply superpixel segmentation and obtain the segments a.k.a. labels using slic().\n",
        "Obtain the segmented image using label2rgb(), passing the segments and profile_image.\n",
        "Detect the faces, using the detector with multi scale method."
      ],
      "metadata": {
        "id": "7J3JWDhp9Bhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the segmentation with default 100 regions\n",
        "segments = slic(profile_image)\n",
        "\n",
        "# Obtain segmented image using label2rgb\n",
        "segmented_image = label2rgb(segments, profile_image, kind='avg')\n",
        "\n",
        "# Detect the faces with multi scale method\n",
        "detected = detector.detect_multi_scale(img=segmented_image,\n",
        "                                       scale_factor=1.2,\n",
        "                                       step_ratio=1,\n",
        "                                       min_size=(10, 10), max_size=(1000, 1000))\n",
        "\n",
        "# Show the detected faces\n",
        "show_detected_face(segmented_image, detected)"
      ],
      "metadata": {
        "id": "c0XqViS-9B1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Privacy protection\n",
        "Let's look at a real-world application of what you have learned in the course.\n",
        "\n",
        "In this exercise, you will detect human faces in the image and for the sake of privacy, you will anonymize data by blurring people's faces in the image automatically.\n",
        "\n",
        "Group band walking\n",
        "Image preloaded as group_image.\n",
        "You can use the gaussian filter for the blurriness.\n",
        "\n",
        "The face detector is ready to use as detector and all packages needed have been imported.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Detect the faces in the image using the detector, set the minimum size of the searching window to 10 by 10 pixels.\n",
        "Go through each detected face with a for loop.\n",
        "Apply a gaussian filter to detect and blur faces, using a sigma of 8."
      ],
      "metadata": {
        "id": "HGYQO0UQ9oYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect the faces\n",
        "detected = detector.detect_multi_scale(img=group_image,\n",
        "                                       scale_factor=1.2, step_ratio=1,\n",
        "                                       min_size=(10, 10), max_size=(100, 100))\n",
        "# For each detected face\n",
        "for d in detected:\n",
        "    # Obtain the face rectangle from detected coordinates\n",
        "    face = getFaceRectangle(d)\n",
        "\n",
        "    # Apply gaussian filter to extracted face\n",
        "    blurred_face = gaussian(face, multichannel=True, sigma = 8)\n",
        "\n",
        "    # Merge this blurry face to our final image and show it\n",
        "    resulting_image = mergeBlurryFace(group_image, blurred_face)\n",
        "show_image(resulting_image, \"Blurred faces\")"
      ],
      "metadata": {
        "id": "Xz5bl0to9opx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Help Sally restore her graduation photo\n",
        "You are going to combine all the knowledge you acquired throughout the course to complete a final challenge: reconstructing a very damaged photo.\n",
        "\n",
        "Help Sally restore her favorite portrait which was damaged by noise, distortion, and missing information due to a breach in her laptop.\n",
        "\n",
        "Sally damaged picture\n",
        "Sally's damaged portrait is already loaded as damaged_image.\n",
        "You will be fixing the problems of this image by:\n",
        "\n",
        "Rotating it to be uprightusing rotate()\n",
        "Applying noise reduction with denoise_tv_chambolle()\n",
        "Reconstructing the damaged parts with inpaint_biharmonic() from the inpaint module.\n",
        "show_image() is already preloaded.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the necessary module to apply restoration on the image.\n",
        "Rotate the image by calling the function rotate().\n",
        "Use the chambolle algorithm to remove the noise from the image.\n",
        "With the mask provided, use the biharmonic method to restore the missing parts of the image and obtain the final image."
      ],
      "metadata": {
        "id": "YBI6Lt6h90yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from skimage.restoration import denoise_tv_chambolle, inpaint\n",
        "from skimage.transform import rotate\n",
        "\n",
        "# Transform the image so it's not rotated\n",
        "upright_img = rotate(damaged_image, 20)\n",
        "\n",
        "# Remove noise from the image, using the chambolle method\n",
        "upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
        "\n",
        "# Reconstruct the image missing parts\n",
        "mask = get_mask(upright_img)\n",
        "result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
        "\n",
        "show_image(result)"
      ],
      "metadata": {
        "id": "Uld5JrKM91HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module End ---"
      ],
      "metadata": {
        "id": "F3UdKwAz-ErB"
      }
    }
  ]
}