{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIufrf6ISJNIoc/oJesHlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_6_Cluster_Analysis_In_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "61sd4LpD_eLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pokémon sightings\n",
        "There have been reports of sightings of rare, legendary Pokémon. You have been asked to investigate! Plot the coordinates of sightings to find out where the Pokémon might be. The X and Y coordinates of the points are stored in list x and y, respectively.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the pyplot class from matplotlib library as plt.\n",
        "Create a scatter plot using the pyplot class.\n",
        "Display the scatter plot created in the earlier step."
      ],
      "metadata": {
        "id": "2hYtpOVs_htN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aQ1r63_8xtB"
      },
      "outputs": [],
      "source": [
        "# Import plotting class from matplotlib library\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(x, y)\n",
        "\n",
        "# Display the scatter plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pokémon sightings: hierarchical clustering\n",
        "We are going to continue the investigation into the sightings of legendary Pokémon from the previous exercise. Remember that in the scatter plot of the previous exercise, you identified two areas where Pokémon sightings were dense. This means that the points seem to separate into two clusters. In this exercise, you will form two clusters of the sightings using hierarchical clustering.\n",
        "\n",
        "'x' and 'y' are columns of X and Y coordinates of the locations of sightings, stored in a pandas DataFrame, df. The following are available for use: matplotlib.pyplot as plt, seaborn as sns, and pandas as pd.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the linkage and fcluster libraries.\n",
        "Use the linkage() function to compute distances using the ward method.\n",
        "Generate cluster labels for each data point with two clusters using the fcluster() function.\n",
        "Plot the points with seaborn and assign a different color to each cluster."
      ],
      "metadata": {
        "id": "oEHbWwSTD1ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import linkage and fcluster functions\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "# Use the linkage() function to compute distance\n",
        "Z = linkage(df, 'ward')\n",
        "\n",
        "# Generate cluster labels\n",
        "df['cluster_labels'] = fcluster(Z, 2, criterion='maxclust')\n",
        "\n",
        "# Plot the points with seaborn\n",
        "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PkfMSPd_D1vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pokémon sightings: k-means clustering\n",
        "We are going to continue the investigation into the sightings of legendary Pokémon from the previous exercise. Just like the previous exercise, we will use the same example of Pokémon sightings. In this exercise, you will form clusters of the sightings using k-means clustering.\n",
        "\n",
        "x and y are columns of X and Y coordinates of the locations of sightings, stored in a pandas DataFrame, df. The following are available for use: matplotlib.pyplot as plt, seaborn as sns, and pandas as pd.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the kmeans and vq functions.\n",
        "Use the kmeans() function to compute cluster centers by defining two clusters.\n",
        "Assign cluster labels to each data point using vq() function.\n",
        "Plot the points"
      ],
      "metadata": {
        "id": "7AT6207E8Beo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import kmeans and vq functions\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "\n",
        "# Compute cluster centers\n",
        "centroids,_ = kmeans(df, 2)\n",
        "\n",
        "# Assign cluster labels\n",
        "df['cluster_labels'], _ = vq(df, centroids)\n",
        "\n",
        "# Plot the points with seaborn\n",
        "sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vojuods78B3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize basic list data\n",
        "Now that you are aware of normalization, let us try to normalize some data. goals_for is a list of goals scored by a football team in their last ten matches. Let us standardize the data using the whiten() function.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the whiten function.\n",
        "Use the whiten() function to standardize the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "gNI0di1HAAWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the whiten function\n",
        "from scipy.cluster.vq import whiten\n",
        "\n",
        "goals_for = [4,3,2,3,1,1,2,0,1,4]\n",
        "\n",
        "# Use the whiten() function to standardize the data\n",
        "scaled_data = whiten(goals_for)\n",
        "print(scaled_data)"
      ],
      "metadata": {
        "id": "-stK41VIADEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize normalized data\n",
        "After normalizing your data, you can compare the scaled data to the original data to see the difference. The variables from the last exercise, goals_for and scaled_data are already available to you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Use the matplotlib library to plot the original and scaled data.\n",
        "Show the legend in the plot.\n",
        "Display the plot."
      ],
      "metadata": {
        "id": "bp2xxz-H3yw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot original data\n",
        "plt.plot(goals_for, label='original')\n",
        "\n",
        "# Plot scaled data\n",
        "plt.plot(scaled_data, label='scaled')\n",
        "\n",
        "# Show the legend in the plot\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roGZ2-do3zEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization of small numbers\n",
        "In earlier examples, you have normalization of whole numbers. In this exercise, you will look at the treatment of fractional numbers - the change of interest rates in the country of Bangalla over the years. For your use, matplotlib.pyplot is imported as plt.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Scale the list rate_cuts, which contains the changes in interest rates.\n",
        "Plot the original data against the scaled data."
      ],
      "metadata": {
        "id": "lHfPMSqr5Buu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "rate_cuts = [0.0025, 0.001, -0.0005, -0.001, -0.0005, 0.0025, -0.001, -0.0015, -0.001, 0.0005]\n",
        "\n",
        "# Use the whiten() function to standardize the data\n",
        "scaled_data = whiten(rate_cuts)\n",
        "\n",
        "# Plot original data\n",
        "plt.plot(rate_cuts, label='original')\n",
        "\n",
        "# Plot scaled data\n",
        "plt.plot(scaled_data, label='scaled')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GLSkcqi75B-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIFA 18: Normalize data\n",
        "FIFA 18 is a football video game that was released in 2017 for PC and consoles. The dataset that you are about to work on contains data on the 1000 top individual players in the game. You will explore various features of the data as we move ahead in the course. In this exercise, you will work with two columns, eur_wage, the wage of a player in Euros and eur_value, their current transfer market value.\n",
        "\n",
        "The data for this exercise is stored in a pandas DataFrame, fifa. whiten from scipy.cluster.vq and matplotlib.pyplot as plt have been pre-loaded.\n",
        "\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Scale the values of eur_wage and eur_value using the whiten() function."
      ],
      "metadata": {
        "id": "A5q3p8dB5XZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale wage and value\n",
        "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
        "fifa['scaled_value'] = whiten(fifa['eur_value'])"
      ],
      "metadata": {
        "id": "B4xEC2pn5Xt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Plot the scaled wages and transfer values of players using the .plot() method of pandas."
      ],
      "metadata": {
        "id": "H-CvrJ9O5a9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale wage and value\n",
        "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
        "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
        "\n",
        "# Plot the two columns in a scatter plot\n",
        "fifa.plot(x='scaled_wage', y='scaled_value', kind='scatter')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5cYcA1pu5bUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIFA 18: Normalize data\n",
        "FIFA 18 is a football video game that was released in 2017 for PC and consoles. The dataset that you are about to work on contains data on the 1000 top individual players in the game. You will explore various features of the data as we move ahead in the course. In this exercise, you will work with two columns, eur_wage, the wage of a player in Euros and eur_value, their current transfer market value.\n",
        "\n",
        "The data for this exercise is stored in a pandas DataFrame, fifa. whiten from scipy.cluster.vq and matplotlib.pyplot as plt have been pre-loaded.\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "Check the mean and standard deviation of the scaled data using the .describe() method of pandas."
      ],
      "metadata": {
        "id": "rlyHloiq6H5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale wage and value\n",
        "fifa['scaled_wage'] = whiten(fifa['eur_wage'])\n",
        "fifa['scaled_value'] = whiten(fifa['eur_value'])\n",
        "\n",
        "# Plot the two columns in a scatter plot\n",
        "fifa.plot(x='scaled_wage', y='scaled_value', kind = 'scatter')\n",
        "plt.show()\n",
        "\n",
        "# Check mean and standard deviation of scaled values\n",
        "print(fifa[['scaled_wage', 'scaled_value']].describe())"
      ],
      "metadata": {
        "id": "GGdIuLNr6IK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical clustering: ward method\n",
        "It is time for Comic-Con! Comic-Con is an annual comic-based convention held in major cities in the world. You have the data of last year's footfall, the number of people at the convention ground at a given time. You would like to decide the location of your stall to maximize sales. Using the ward method, apply hierarchical clustering to find the two points of attraction in the area.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import fcluster and linkage from scipy.cluster.hierarchy.\n",
        "Use the ward method in the linkage() function.\n",
        "Assign cluster labels by forming 2 flat clusters from distance_matrix.\n",
        "Run the plotting code to see the results."
      ],
      "metadata": {
        "id": "E6augUEtC_bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the fcluster and linkage functions\n",
        "from scipy.cluster.hierarchy import fcluster, linkage\n",
        "\n",
        "# Use the linkage() function\n",
        "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'ward', metric = 'euclidean')\n",
        "\n",
        "# Assign cluster labels\n",
        "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion='maxclust')\n",
        "\n",
        "# Plot clusters\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qasnLu5oC_rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical clustering: single method\n",
        "Let us use the same footfall dataset and check if any changes are seen if we use a different method for clustering.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import fcluster and linkage from scipy.cluster.hierarchy.\n",
        "Use the single method in the linkage() function."
      ],
      "metadata": {
        "id": "kX3tCcOHD00R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the fcluster and linkage functions\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "\n",
        "# Use the linkage() function\n",
        "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']], method = 'single', metric = 'euclidean')\n",
        "\n",
        "# Assign cluster labels\n",
        "comic_con['cluster_labels'] = fcluster(distance_matrix, 2, criterion = 'maxclust')\n",
        "\n",
        "# Plot clusters\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzJ0LF9_D1Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical clustering: complete method\n",
        "For the third and final time, let us use the same footfall dataset and check if any changes are seen if we use a different method for clustering.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import fcluster and linkage from scipy.cluster.hierarchy.\n",
        "Use the complete method in the .linkage() function."
      ],
      "metadata": {
        "id": "s-7fMigYep6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the fcluster and linkage functions\n",
        "from scipy.cluster.hierarchy import fcluster, linkage\n",
        "\n",
        "# Use the linkage() function\n",
        "distance_matrix = linkage(comic_con[['x_scaled', 'y_scaled']],\n",
        "                        method = 'complete',\n",
        "                        metric = 'euclidean')\n",
        "\n",
        "# Assign cluster labels\n",
        "comic_con['cluster_labels'] = fcluster(distance_matrix, 2,\n",
        "                            criterion = 'maxclust')\n",
        "\n",
        "# Plot clusters\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8rvdApwzeqQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize clusters with matplotlib\n",
        "We have discussed that visualizations are necessary to assess the clusters that are formed and spot trends in your data. Let us now focus on visualizing the footfall dataset from Comic-Con using the matplotlib module.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the pyplot class from matplotlib module as plt.\n",
        "Define a colors dictionary for two cluster labels, 1 and 2.\n",
        "Plot a scatter plot with colors for each cluster as defined by the colors dictionary."
      ],
      "metadata": {
        "id": "kihymH4yiW-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pyplot class\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Define a colors dictionary for clusters\n",
        "colors = {1:'red', 2:'blue'}\n",
        "\n",
        "# Plot a scatter plot\n",
        "comic_con.plot.scatter(x='x_scaled',\n",
        "                \t   y='y_scaled',\n",
        "                \t   c=comic_con['cluster_labels'].apply(lambda x: colors[x]))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7qTgDcDTiXXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize clusters with seaborn\n",
        "Let us now visualize the footfall dataset from Comic Con using the seaborn module. Visualizing clusters using seaborn is easier with the inbuild hue function for cluster labels.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the seaborn module as sns.\n",
        "Plot a scatter plot using the .scatterplot() method of seaborn, with the cluster labels as the hue argument."
      ],
      "metadata": {
        "id": "R10yio1P1h5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the seaborn module\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot a scatter plot using seaborn\n",
        "sns.scatterplot(x='x_scaled',\n",
        "                y='y_scaled',\n",
        "                hue='cluster_labels',\n",
        "                data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dhvm82GY1iK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a dendrogram\n",
        "Dendrograms are branching diagrams that show the merging of clusters as we move through the distance matrix. Let us use the Comic Con footfall data to create a dendrogram.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time. cluster_labels has the cluster labels. A linkage object is stored in the variable distance_matrix.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import the dendrogram function from scipy.cluster.hierarchy.\n",
        "Create a dendrogram using the linkage object.\n",
        "Display the dendrogram using .show() method of the plt object."
      ],
      "metadata": {
        "id": "Vv20gf1_3iYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dendrogram function\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "# Create a dendrogram\n",
        "dn = dendrogram(distance_matrix)\n",
        "\n",
        "# Display the dendogram\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zcMUREb43izv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIFA 18: exploring defenders\n",
        "In the FIFA 18 dataset, various attributes of players are present. Two such attributes are:\n",
        "\n",
        "sliding tackle: a number between 0-99 which signifies how accurate a player is able to perform sliding tackles\n",
        "aggression: a number between 0-99 which signifies the commitment and will of a player\n",
        "These are typically high in defense-minded players. In this exercise, you will perform clustering based on these attributes in the data.\n",
        "\n",
        "This data consists of 5000 rows, and is considerably larger than earlier datasets. Running hierarchical clustering on this data can take up to 10 seconds.\n",
        "\n",
        "The following modules are pre-loaded: dendrogram, linkage, fcluster from scipy.cluster.hierarchy, matplotlib.pyplot as plt, seaborn as sns. The data is stored in a pandas DataFrame, fifa.\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Fit the scaled data in columns scaled_sliding_tackle and scaled_aggression into a hierarchical clustering algorithm. Additionally, you may want to check how long it takes to run the data using the timeit module."
      ],
      "metadata": {
        "id": "0HAx2kTytq84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data into a hierarchical clustering algorithm\n",
        "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')"
      ],
      "metadata": {
        "id": "3bCD8Jz-trUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Assign cluster labels to each row in the data using the fcluster() function (use 3 clusters)."
      ],
      "metadata": {
        "id": "WaLh6B-ot_UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data into a hierarchical clustering algorithm\n",
        "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
        "\n",
        "# Assign cluster labels to each row of data\n",
        "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')"
      ],
      "metadata": {
        "id": "nrROjs_Rt_dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "4\n",
        "Display cluster centers of each cluster with respect to the scaled columns by calculating the mean value for each cluster."
      ],
      "metadata": {
        "id": "BNIMp46ruLXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data into a hierarchical clustering algorithm\n",
        "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
        "\n",
        "# Assign cluster labels to each row of data\n",
        "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
        "\n",
        "# Display cluster centers of each cluster\n",
        "print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())"
      ],
      "metadata": {
        "id": "DNBOo4GPuLgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "Create a scatter plot using seaborn with the scaled_sliding_tackle attribute on the x-axis and the scaled_aggression attribute on the y-axis. Assign a different color to each cluster."
      ],
      "metadata": {
        "id": "m2vjpH5OuXnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data into a hierarchical clustering algorithm\n",
        "distance_matrix = linkage(fifa[['scaled_sliding_tackle', 'scaled_aggression']], 'ward')\n",
        "\n",
        "# Assign cluster labels to each row of data\n",
        "fifa['cluster_labels'] = fcluster(distance_matrix, 3, criterion='maxclust')\n",
        "\n",
        "# Display cluster centers of each cluster\n",
        "print(fifa[['scaled_sliding_tackle', 'scaled_aggression', 'cluster_labels']].groupby('cluster_labels').mean())\n",
        "\n",
        "# Create a scatter plot through seaborn\n",
        "sns.scatterplot(x='scaled_sliding_tackle', y='scaled_aggression', hue='cluster_labels', data=fifa)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9c6peI9GuX8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means clustering: first exercise\n",
        "This exercise will familiarize you with the usage of k-means clustering on a dataset. Let us use the Comic Con dataset and check how k-means clustering works on it.\n",
        "\n",
        "Recall the two steps of k-means clustering:\n",
        "\n",
        "Define cluster centers through kmeans() function. It has two required arguments: observations and number of clusters.\n",
        "Assign cluster labels through the vq() function. It has two required arguments: observations and cluster centers.\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import kmeans and vq functions in SciPy.\n",
        "Generate cluster centers using the kmeans() function with two clusters.\n",
        "Create cluster labels using these cluster centers.\n",
        "\n"
      ],
      "metadata": {
        "id": "-EPJwfWMxWyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the kmeans and vq functions\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "\n",
        "# Generate cluster centers\n",
        "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
        "\n",
        "# Assign cluster labels\n",
        "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)\n",
        "\n",
        "# Plot clusters\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xegAIfM6xXTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elbow method on distinct clusters\n",
        "Let us use the comic con dataset to see how the elbow plot looks on a dataset with distinct, well-defined clusters. You may want to display the data points before proceeding with the exercise.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Create a list of distortions for each cluster in num_clusters.\n",
        "Create a DataFrame elbow_plot with num_clusters and distortions.\n",
        "With the .lineplot() method, plot elbow_plot with num_clusters in the x axis and distortions in the y axis."
      ],
      "metadata": {
        "id": "Rl6n0uoVAebk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distortions = []\n",
        "num_clusters = range(1, 7)\n",
        "\n",
        "# Create a list of distortions from the kmeans function\n",
        "for i in num_clusters:\n",
        "    cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], i)\n",
        "    distortions.append(distortion)\n",
        "\n",
        "# Create a DataFrame with two lists - num_clusters, distortions\n",
        "elbow_plot = pd.DataFrame({'num_clusters': num_clusters,\n",
        "                            'distortions': distortions})\n",
        "\n",
        "# Creat a line plot of num_clusters and distortions\n",
        "sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
        "plt.xticks(num_clusters)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eYuJG6NBAe2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elbow method on uniform data\n",
        "In the earlier exercise, you constructed an elbow plot on data with well-defined clusters. Let us now see how the elbow plot looks on a dataset with uniformly distributed points. You may want to display the data points before proceeding with the exercise.\n",
        "\n",
        "The data is stored in a pandas DataFrame, uniform_data. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of points.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "2\n",
        "Create a list of distortions for each cluster in num_clusters.\n",
        "Create a DataFrame elbow_plot with num_clusters and distortions.\n",
        "With the .lineplot() method, plot elbow_plot with num_clusters in the x axis and distortions in the y axis."
      ],
      "metadata": {
        "id": "5zVahcX1BMOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distortions = []\n",
        "num_clusters = range(2, 7)\n",
        "\n",
        "# Create a list of distortions from the kmeans function\n",
        "for i in num_clusters:\n",
        "    cluster_centers, distortion = kmeans(uniform_data[['x_scaled', 'y_scaled']], i)\n",
        "    distortions.append(distortion)\n",
        "\n",
        "# Create a DataFrame with two lists - number of clusters and distortions\n",
        "elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
        "\n",
        "# Creat a line plot of num_clusters and distortions\n",
        "sns.lineplot(x='num_clusters', y='distortions', data=elbow_plot)\n",
        "plt.xticks(num_clusters)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BZc67jYlBMkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impact of seeds on distinct clusters\n",
        "You noticed the impact of seeds on a dataset that did not have well-defined groups of clusters. In this exercise, you will explore whether seeds impact the clusters in the Comic Con data, where the clusters are well-defined.\n",
        "\n",
        "The data is stored in a pandas DataFrame, comic_con. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of people at a given point in time.\n",
        "\n",
        "Instructions 1/2\n",
        "50 XP\n",
        "Import the random class from numpy and initialize the seed with the integer 0.\n",
        "\n",
        "2\n",
        "Change your code from the earlier step so that the seed is initialized with a list [1, 2, 1000]."
      ],
      "metadata": {
        "id": "qqaTeb7nZbI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import random class\n",
        "from numpy import random\n",
        "\n",
        "# Initialize seed\n",
        "random.seed(0)\n",
        "\n",
        "# Run kmeans clustering\n",
        "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
        "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)\n",
        "\n",
        "# Plot the scatterplot\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eZnUbCCkZdyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/2\n",
        "\n",
        "Change your code from the earlier step so that the seed is initialized with a list [1, 2, 1000]."
      ],
      "metadata": {
        "id": "wnJo9-wTZgzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import random class\n",
        "from numpy import random\n",
        "\n",
        "# Initialize seed\n",
        "random.seed([1, 2, 1000])\n",
        "\n",
        "# Run kmeans clustering\n",
        "cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
        "comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']], cluster_centers)\n",
        "\n",
        "# Plot the scatterplot\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = comic_con)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aLQ6PhkpZiVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uniform clustering patterns\n",
        "Now that you are familiar with the impact of seeds, let us look at the bias in k-means clustering towards the formation of uniform clusters.\n",
        "\n",
        "Let us use a mouse-like dataset for our next exercise. A mouse-like dataset is a group of points that resemble the head of a mouse: it has three clusters of points arranged in circles, one each for the face and two ears of a mouse.\n",
        "\n",
        "Here is how a typical mouse-like dataset looks like (Source - https://www.researchgate.net/figure/Clustering-results-for-the-Mouse-data-set-where-the-black-boxes-represent-the-centroids_fig3_256378655).\n",
        "\n",
        "\n",
        "\n",
        "The data is stored in a pandas DataFrame, mouse. x_scaled and y_scaled are the column names of the standardized X and Y coordinates of the data points.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Import kmeans and vq functions in SciPy.\n",
        "Generate cluster centers using the kmeans() function with three clusters.\n",
        "Create cluster labels with vq() with the cluster centers generated above."
      ],
      "metadata": {
        "id": "Edoxaw5UaZJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the kmeans and vq functions\n",
        "from scipy.cluster.vq import kmeans, vq\n",
        "\n",
        "# Generate cluster centers\n",
        "cluster_centers, distortion = kmeans(mouse[['x_scaled', 'y_scaled']], 3)\n",
        "\n",
        "# Assign cluster labels\n",
        "mouse['cluster_labels'], distortion_list = vq(mouse[['x_scaled', 'y_scaled']], cluster_centers)\n",
        "\n",
        "# Plot clusters\n",
        "sns.scatterplot(x='x_scaled', y='y_scaled',\n",
        "                hue='cluster_labels', data = mouse)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jduy9MI1aiYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FIFA 18: defenders revisited\n",
        "In the FIFA 18 dataset, various attributes of players are present. Two such attributes are:\n",
        "\n",
        "defending: a number which signifies the defending attributes of a player\n",
        "physical: a number which signifies the physical attributes of a player\n",
        "These are typically defense-minded players. In this exercise, you will perform clustering based on these attributes in the data.\n",
        "\n",
        "The following modules have been pre-loaded: kmeans, vq from scipy.cluster.vq, matplotlib.pyplot as plt, seaborn as sns. The data for this exercise is stored in a pandas DataFrame, fifa. The scaled variables are scaled_def and scaled_phy.\n",
        "\n",
        "Instructions 1/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Initialize the random seed to the list [1000,2000]."
      ],
      "metadata": {
        "id": "lrZuNYBTaxKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a random seed in numpy\n",
        "random.seed([1000, 2000])"
      ],
      "metadata": {
        "id": "HJc5OCZjaxot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Fit the scaled data in columns scaled_def and scaled_phy into a k-means clustering algorithm with 3 clusters and assign cluster labels."
      ],
      "metadata": {
        "id": "c0RiBquqa0u9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a random seed in numpy\n",
        "random.seed([1000,2000])\n",
        "\n",
        "# Fit the data into a k-means algorithm\n",
        "cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)\n",
        "\n",
        "# Assign cluster labels\n",
        "fifa['cluster_labels'],_ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)"
      ],
      "metadata": {
        "id": "ph_qPSGga1Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Display cluster centers of each cluster with respect to the scaled columns by calculating the mean value for each cluster."
      ],
      "metadata": {
        "id": "ZILrUwn1bXts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a random seed in numpy\n",
        "random.seed([1000,2000])\n",
        "\n",
        "# Fit the data into a k-means algorithm\n",
        "cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)\n",
        "\n",
        "# Assign cluster labels\n",
        "fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)\n",
        "\n",
        "# Display cluster centers\n",
        "print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())"
      ],
      "metadata": {
        "id": "qLUwdK2pbYKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "Create a seaborn scatter plot with scaled_def on the x-axis and scaled_phy on the y-axis, with each cluster represented by a different color."
      ],
      "metadata": {
        "id": "QCxLWGB2bs3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a random seed in numpy\n",
        "random.seed([1000,2000])\n",
        "\n",
        "# Fit the data into a k-means algorithm\n",
        "cluster_centers,_ = kmeans(fifa[['scaled_def', 'scaled_phy']], 3)\n",
        "\n",
        "# Assign cluster labels\n",
        "fifa['cluster_labels'], _ = vq(fifa[['scaled_def', 'scaled_phy']], cluster_centers)\n",
        "\n",
        "# Display cluster centers\n",
        "print(fifa[['scaled_def', 'scaled_phy', 'cluster_labels']].groupby('cluster_labels').mean())\n",
        "\n",
        "# Create a scatter plot through seaborn\n",
        "sns.scatterplot(x='scaled_def', y='scaled_phy', hue='cluster_labels', data=fifa)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HwyHTdMybtJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}