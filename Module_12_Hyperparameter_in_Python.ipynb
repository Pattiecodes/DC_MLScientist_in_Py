{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU1xp7Hop2YNxoKQVGv+w4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_12_Hyperparameter_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "-VcIrbIjQEkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting a Logistic Regression parameter\n",
        "You are now going to practice extracting an important parameter of the logistic regression model. The logistic regression has a few other parameters you will not explore here but you can review them in the scikit-learn.org documentation for the LogisticRegression() module under 'Attributes'.\n",
        "\n",
        "This parameter is important for understanding the direction and magnitude of the effect the variables have on the target.\n",
        "\n",
        "In this exercise we will extract the coefficient parameter (found in the coef_ attribute), zip it up with the original column names, and see which variables had the largest positive effect on the target variable.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "A logistic regression model object named log_reg_clf\n",
        "The X_train DataFrame\n",
        "sklearn and pandas have been imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a list of the original column names used in the training DataFrame.\n",
        "Extract the coefficients of the logistic regression estimator.\n",
        "Create a DataFrame of coefficients and variable names & view it.\n",
        "Print out the top 3 'positive' variables based on the coefficient size."
      ],
      "metadata": {
        "id": "AlRQVUS9QG5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxXSwXIOt8Oy"
      },
      "outputs": [],
      "source": [
        "# Create a list of original variable names from the training DataFrame\n",
        "original_variables = list(X_train.columns)\n",
        "\n",
        "# Extract the coefficients of the logistic regression estimator\n",
        "model_coefficients = log_reg_clf.coef_[0]\n",
        "\n",
        "# Create a dataframe of the variables and coefficients & print it out\n",
        "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
        "print(coefficient_df)\n",
        "\n",
        "# Print out the top 3 positive variables\n",
        "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, ascending=False)[0:3]\n",
        "print(top_three_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting a Random Forest parameter\n",
        "You will now translate the work previously undertaken on the logistic regression model to a random forest model. A parameter of this model is, for a given tree, how it decided to split at each level.\n",
        "\n",
        "This analysis is not as useful as the coefficients of logistic regression as you will be unlikely to ever explore every split and every tree in a random forest model. However, it is a very useful exercise to peek under the hood at what the model is doing.\n",
        "\n",
        "In this exercise we will extract a single tree from our random forest model, visualize it and programmatically extract one of the splits.\n",
        "\n",
        "You have available:\n",
        "\n",
        "A random forest model object, rf_clf\n",
        "An image of the top of the chosen decision tree, tree_viz_image\n",
        "The X_train DataFrame & the original_variables list\n",
        "Instructions\n",
        "100 XP\n",
        "Extract the 7th tree (6th index) from the random forest model.\n",
        "Visualize this tree (tree_viz_image) to see the split decisions.\n",
        "Extract the feature & level of the top split.\n",
        "Print out the feature and level together."
      ],
      "metadata": {
        "id": "zsZDabeKRFeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the 7th (index 6) tree from the random forest\n",
        "chosen_tree = rf_clf.estimators_[6]\n",
        "\n",
        "# Visualize the graph using the provided image\n",
        "imgplot = plt.imshow(tree_viz_image)\n",
        "plt.show()\n",
        "\n",
        "# Extract the parameters and level of the top (index 0) node\n",
        "split_column = chosen_tree.tree_.feature[0]\n",
        "split_column_name = X_train.columns[split_column]\n",
        "split_value = chosen_tree.tree_.threshold[0]\n",
        "\n",
        "# Print out the feature and level\n",
        "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))"
      ],
      "metadata": {
        "id": "i3eyjuATRFyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Random Forest Hyperparameters\n",
        "Understanding what hyperparameters are available and the impact of different hyperparameters is a core skill for any data scientist. As models become more complex, there are many different settings you can set, but only some will have a large impact on your model.\n",
        "\n",
        "You will now assess an existing random forest model (it has some bad choices for hyperparameters!) and then make better choices for a new random forest model and assess its performance.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "X_train, X_test, y_train, y_test DataFrames\n",
        "An existing pre-trained random forest estimator, rf_clf_old\n",
        "The predictions of the existing random forest estimator on the test set, rf_old_predictions\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Print out the hyperparameters of the existing random forest classifier by printing the estimator and then create a confusion matrix and accuracy score from it. The test set y_test and the old predictions rf_old_predictions will be quite useful!"
      ],
      "metadata": {
        "id": "GGLEMynXS-DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  \tconfusion_matrix(y_test, rf_old_predictions),\n",
        "  \taccuracy_score(y_test, rf_old_predictions)))"
      ],
      "metadata": {
        "id": "GJEx5wiyS-Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "3\n",
        "Create a new random forest classifier with a better n_estimators (try 500) then fit this to the data and obtain predictions."
      ],
      "metadata": {
        "id": "Qq9ly92lTVeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  confusion_matrix(y_test, rf_old_predictions),\n",
        "  accuracy_score(y_test, rf_old_predictions)))\n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)"
      ],
      "metadata": {
        "id": "K_Fie0AdTVw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "30 XP\n",
        "Assess the performance of the new random forest classifier. Create the confusion matrix and accuracy score and print them out. How does this compare to the first model you were given?"
      ],
      "metadata": {
        "id": "rPChXiXmTfqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  confusion_matrix(y_test, rf_old_predictions),\n",
        "  accuracy_score(y_test, rf_old_predictions)))\n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Assess the new model (using new predictions!)\n",
        "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, rf_new_predictions))\n",
        "print(\"Accuracy Score: \\n\\n\", accuracy_score(y_test, rf_new_predictions))"
      ],
      "metadata": {
        "id": "OyOlkEtmTfzo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}