{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyOfoANzrE21ECgZ2ze6cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pattiecodes/DC_MLScientist_in_Py/blob/main/Module_12_Hyperparameter_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module Start ---"
      ],
      "metadata": {
        "id": "-VcIrbIjQEkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting a Logistic Regression parameter\n",
        "You are now going to practice extracting an important parameter of the logistic regression model. The logistic regression has a few other parameters you will not explore here but you can review them in the scikit-learn.org documentation for the LogisticRegression() module under 'Attributes'.\n",
        "\n",
        "This parameter is important for understanding the direction and magnitude of the effect the variables have on the target.\n",
        "\n",
        "In this exercise we will extract the coefficient parameter (found in the coef_ attribute), zip it up with the original column names, and see which variables had the largest positive effect on the target variable.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "A logistic regression model object named log_reg_clf\n",
        "The X_train DataFrame\n",
        "sklearn and pandas have been imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a list of the original column names used in the training DataFrame.\n",
        "Extract the coefficients of the logistic regression estimator.\n",
        "Create a DataFrame of coefficients and variable names & view it.\n",
        "Print out the top 3 'positive' variables based on the coefficient size."
      ],
      "metadata": {
        "id": "AlRQVUS9QG5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxXSwXIOt8Oy"
      },
      "outputs": [],
      "source": [
        "# Create a list of original variable names from the training DataFrame\n",
        "original_variables = list(X_train.columns)\n",
        "\n",
        "# Extract the coefficients of the logistic regression estimator\n",
        "model_coefficients = log_reg_clf.coef_[0]\n",
        "\n",
        "# Create a dataframe of the variables and coefficients & print it out\n",
        "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
        "print(coefficient_df)\n",
        "\n",
        "# Print out the top 3 positive variables\n",
        "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, ascending=False)[0:3]\n",
        "print(top_three_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting a Random Forest parameter\n",
        "You will now translate the work previously undertaken on the logistic regression model to a random forest model. A parameter of this model is, for a given tree, how it decided to split at each level.\n",
        "\n",
        "This analysis is not as useful as the coefficients of logistic regression as you will be unlikely to ever explore every split and every tree in a random forest model. However, it is a very useful exercise to peek under the hood at what the model is doing.\n",
        "\n",
        "In this exercise we will extract a single tree from our random forest model, visualize it and programmatically extract one of the splits.\n",
        "\n",
        "You have available:\n",
        "\n",
        "A random forest model object, rf_clf\n",
        "An image of the top of the chosen decision tree, tree_viz_image\n",
        "The X_train DataFrame & the original_variables list\n",
        "Instructions\n",
        "100 XP\n",
        "Extract the 7th tree (6th index) from the random forest model.\n",
        "Visualize this tree (tree_viz_image) to see the split decisions.\n",
        "Extract the feature & level of the top split.\n",
        "Print out the feature and level together."
      ],
      "metadata": {
        "id": "zsZDabeKRFeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the 7th (index 6) tree from the random forest\n",
        "chosen_tree = rf_clf.estimators_[6]\n",
        "\n",
        "# Visualize the graph using the provided image\n",
        "imgplot = plt.imshow(tree_viz_image)\n",
        "plt.show()\n",
        "\n",
        "# Extract the parameters and level of the top (index 0) node\n",
        "split_column = chosen_tree.tree_.feature[0]\n",
        "split_column_name = X_train.columns[split_column]\n",
        "split_value = chosen_tree.tree_.threshold[0]\n",
        "\n",
        "# Print out the feature and level\n",
        "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))"
      ],
      "metadata": {
        "id": "i3eyjuATRFyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Random Forest Hyperparameters\n",
        "Understanding what hyperparameters are available and the impact of different hyperparameters is a core skill for any data scientist. As models become more complex, there are many different settings you can set, but only some will have a large impact on your model.\n",
        "\n",
        "You will now assess an existing random forest model (it has some bad choices for hyperparameters!) and then make better choices for a new random forest model and assess its performance.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "X_train, X_test, y_train, y_test DataFrames\n",
        "An existing pre-trained random forest estimator, rf_clf_old\n",
        "The predictions of the existing random forest estimator on the test set, rf_old_predictions\n",
        "Instructions 1/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Print out the hyperparameters of the existing random forest classifier by printing the estimator and then create a confusion matrix and accuracy score from it. The test set y_test and the old predictions rf_old_predictions will be quite useful!"
      ],
      "metadata": {
        "id": "GGLEMynXS-DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  \tconfusion_matrix(y_test, rf_old_predictions),\n",
        "  \taccuracy_score(y_test, rf_old_predictions)))"
      ],
      "metadata": {
        "id": "GJEx5wiyS-Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "3\n",
        "Create a new random forest classifier with a better n_estimators (try 500) then fit this to the data and obtain predictions."
      ],
      "metadata": {
        "id": "Qq9ly92lTVeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  confusion_matrix(y_test, rf_old_predictions),\n",
        "  accuracy_score(y_test, rf_old_predictions)))\n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)"
      ],
      "metadata": {
        "id": "K_Fie0AdTVw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "30 XP\n",
        "Assess the performance of the new random forest classifier. Create the confusion matrix and accuracy score and print them out. How does this compare to the first model you were given?"
      ],
      "metadata": {
        "id": "rPChXiXmTfqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the old estimator, notice which hyperparameter is badly set\n",
        "print(rf_clf_old)\n",
        "\n",
        "# Get confusion matrix & accuracy for the old rf_model\n",
        "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
        "  confusion_matrix(y_test, rf_old_predictions),\n",
        "  accuracy_score(y_test, rf_old_predictions)))\n",
        "\n",
        "# Create a new random forest classifier with better hyperparamaters\n",
        "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
        "\n",
        "# Fit this to the data and obtain predictions\n",
        "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Assess the new model (using new predictions!)\n",
        "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, rf_new_predictions))\n",
        "print(\"Accuracy Score: \\n\\n\", accuracy_score(y_test, rf_new_predictions))"
      ],
      "metadata": {
        "id": "OyOlkEtmTfzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters of KNN\n",
        "To apply the concepts learned in the prior exercise, it is good practice to try out learnings on a new algorithm. The k-nearest-neighbors algorithm is not as popular as it used to be but can still be an excellent choice for data that has groups of data that behave similarly. Could this be the case for our credit card users?\n",
        "\n",
        "In this case you will try out several different values for one of the core hyperparameters for the knn algorithm and compare performance.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "X_train, X_test, y_train, y_test DataFrames\n",
        "Instructions\n",
        "100 XP\n",
        "Build a knn estimator for the following values of n_neighbors [5,10,20].\n",
        "Fit each to the training data and produce predictions.\n",
        "Get an accuracy score for each model and print them out."
      ],
      "metadata": {
        "id": "hpnCNU6IUAaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a knn estimator for each value of n_neighbours\n",
        "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
        "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "# Fit each to the training data & produce predictions\n",
        "knn_5_predictions = knn_5.fit(X_train, y_train).predict(X_test)\n",
        "knn_10_predictions = knn_10.fit(X_train, y_train).predict(X_test)\n",
        "knn_20_predictions = knn_20.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "# Get an accuracy score for each of the models\n",
        "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
        "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
        "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
        "print(\"The accuracy of 5, 10, 20 neighbours was {}, {}, {}\".format(knn_5_accuracy, knn_10_accuracy, knn_20_accuracy))"
      ],
      "metadata": {
        "id": "T_iud4a9UArv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automating Hyperparameter Choice\n",
        "Finding the best hyperparameter of interest without writing hundreds of lines of code for hundreds of models is an important efficiency gain that will greatly assist your future machine learning model building.\n",
        "\n",
        "An important hyperparameter for the GBM algorithm is the learning rate. But which learning rate is best for this problem? By writing a loop to search through a number of possibilities, collating these and viewing them you can find the best one.\n",
        "\n",
        "Possible learning rates to try include 0.001, 0.01, 0.05, 0.1, 0.2 and 0.5\n",
        "\n",
        "You will have available X_train, X_test, y_train & y_test datasets, and GradientBoostingClassifier has been imported for you.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a learning_rates list for the learning rates, and a results_list to hold the accuracy score of your predictions.\n",
        "Write a loop to create a GBM model for each learning rate mentioned and create predictions for each model.\n",
        "Save the learning rate and accuracy score to a results_list.\n",
        "Turn the results list into a DataFrame and print it out."
      ],
      "metadata": {
        "id": "ot_DzYCpVRQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rates & results storage\n",
        "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
        "results_list = []\n",
        "\n",
        "# Create the for loop to evaluate model predictions for each learning rate\n",
        "for learning_rate in learning_rates:\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    # Save the learning rate and accuracy score\n",
        "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])\n",
        "\n",
        "# Gather everything into a DataFrame\n",
        "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "aCY4urd_VRjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Learning Curves\n",
        "If we want to test many different values for a single hyperparameter it can be difficult to easily view that in the form of a DataFrame. Previously you learned about a nice trick to analyze this. A graph called a 'learning curve' can nicely demonstrate the effect of increasing or decreasing a particular hyperparameter on the final result.\n",
        "\n",
        "Instead of testing only a few values for the learning rate, you will test many to easily see the effect of this hyperparameter across a large range of values. A useful function from NumPy is np.linspace(start, end, num) which allows you to create a number of values (num) evenly spread within an interval (start, end) that you specify.\n",
        "\n",
        "You will have available X_train, X_test, y_train & y_test datasets.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a list of 30 learning rates evenly spread between 0.01 and 2.\n",
        "Create a similar loop to last exercise but just save out accuracy scores to a list.\n",
        "Plot the learning rates against the accuracy score."
      ],
      "metadata": {
        "id": "_ZMJw5kGVq3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rates & accuracies list\n",
        "learn_rates = np.linspace(0.01, 2, num=30)\n",
        "accuracies = []\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rates:\n",
        "  \t# Create the model, predictions & save the accuracies as before\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate)\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "    accuracies.append(accuracy_score(y_test, predictions))\n",
        "\n",
        "# Plot results\n",
        "plt.plot(learn_rates, accuracies)\n",
        "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6IsOoMIIVrRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Grid Search functions\n",
        "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.\n",
        "\n",
        "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.\n",
        "\n",
        "You will have available the X_train, X_test, y_train and y_test datasets available.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Build a function that takes two parameters called learning_rate and max_depth for the learning rate and maximum depth.\n",
        "Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.\n",
        "Have the function return the results of that model and the chosen hyperparameters (learning_rate and max_depth)."
      ],
      "metadata": {
        "id": "KGtxNnRnW3rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the function\n",
        "def gbm_grid_search(learning_rate, max_depth):\n",
        "\n",
        "\t# Create the model\n",
        "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
        "\n",
        "    # Use the model to make predictions\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "    # Return the hyperparameters and score\n",
        "    return([learning_rate, max_depth, accuracy_score(y_test, predictions)])"
      ],
      "metadata": {
        "id": "xv5U-TgqW4G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iteratively tune multiple hyperparameters\n",
        "In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter.\n",
        "\n",
        "The function gbm_grid_search(learn_rate, max_depth) is available in this exercise.\n",
        "\n",
        "If you need to remind yourself of the function you can run the function print_func() that has been created for you\n",
        "\n",
        "Instructions 1/3\n",
        "0 XP\n",
        "2\n",
        "3\n",
        "Write a for-loop to test the values (0.01, 0.1, 0.5) for the learning_rate and (2, 4, 6) for the max_depth using the function you created gbm_grid_search and print the results."
      ],
      "metadata": {
        "id": "tq6Vx3cpXRCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the relevant lists\n",
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2,4,6]\n",
        "\n",
        "# Create the for loop\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
        "\n",
        "# Print the results\n",
        "print(results_list)"
      ],
      "metadata": {
        "id": "54DNLcXRXRc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "0 XP\n",
        "3\n",
        "Extend the gbm_grid_search function to include the hyperparameter subsample. Name this new function gbm_grid_search_extended.\n",
        "\n"
      ],
      "metadata": {
        "id": "WctJjsSUXg6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "learn_rate_list = [0.01, 0.1, 0.5]\n",
        "max_depth_list = [2,4,6]\n",
        "\n",
        "# Extend the function input\n",
        "def gbm_grid_search_extended(learn_rate, max_depth, subsample):\n",
        "\n",
        "\t# Extend the model creation section\n",
        "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample)\n",
        "\n",
        "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "    # Extend the return part\n",
        "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])"
      ],
      "metadata": {
        "id": "XDhwfkwHXhEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "0 XP\n",
        "Extend your loop to call gbm_grid_search (available in your console), then test the values [0.4 , 0.6] for the subsample hyperparameter and print the results. max_depth_list & learn_rate_list are available in your environment."
      ],
      "metadata": {
        "id": "N6jJdWINXouI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "\n",
        "# Create the new list to test\n",
        "subsample_list = [0.4, 0.6]\n",
        "\n",
        "for learn_rate in learn_rate_list:\n",
        "    for max_depth in max_depth_list:\n",
        "\n",
        "        # Extend the for loop\n",
        "        for subsample in subsample_list:\n",
        "\n",
        "            # Extend the results to include the new hyperparameter\n",
        "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
        "\n",
        "# Print results\n",
        "print(results_list)"
      ],
      "metadata": {
        "id": "REQcVzSKXo9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearchCV with Scikit Learn\n",
        "The GridSearchCV module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a GridSearchCV object with certain parameters.\n",
        "\n",
        "The desired options are:\n",
        "\n",
        "A Random Forest Estimator, with the split criterion as 'entropy'\n",
        "5-fold cross validation\n",
        "The hyperparameters max_depth (2, 4, 8, 15) and max_features ('auto' vs 'sqrt')\n",
        "Use roc_auc to score the models\n",
        "Use 4 cores for processing in parallel\n",
        "Ensure you refit the best model and return training scores\n",
        "You will have available X_train, X_test, y_train & y_test datasets.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a Random Forest estimator as specified in the context above.\n",
        "Create a parameter grid as specified in the context above.\n",
        "Create a GridSearchCV object as outlined in the context ab"
      ],
      "metadata": {
        "id": "9ZfVKQtjYlOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Random Forest Classifier with specified criterion\n",
        "rf_class = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_rf_class=GridSearchCV(\n",
        "    estimator=rf_class,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=4,\n",
        "    cv=5,\n",
        "    refit=True, return_train_score=True)\n",
        "print(grid_rf_class)"
      ],
      "metadata": {
        "id": "E256QpY-Ylfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring the grid search results\n",
        "You will now explore the cv_results_ property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook.\n",
        "\n",
        "A reminder of the different column types in this property:\n",
        "\n",
        "time_ columns\n",
        "param_ columns (one for each hyperparameter) and the singular params column (with all hyperparameter settings)\n",
        "a train_score column for each cv fold including the mean_train_score and std_train_score columns\n",
        "a test_score column for each cv fold including the mean_test_score and std_test_score columns\n",
        "a rank_test_score column with a number from 1 to n (number of iterations) ranking the rows based on their mean_test_score\n",
        "Instructions\n",
        "100 XP\n",
        "Read the cv_results_ property of the grid_rf_class GridSearchCV object into a data frame & print the whole thing out to inspect.\n",
        "Extract & print the singular column containing a dictionary of all hyperparameters used in each iteration of the grid search.\n",
        "Extract & print the row that had the best mean test score by indexing using the rank_test_score column."
      ],
      "metadata": {
        "id": "VFC-4Fi1ZV-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the cv_results property into a dataframe & print it out\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "print(cv_results_df)\n",
        "\n",
        "# Extract and print the column with a dictionary of hyperparameters used\n",
        "column = cv_results_df.loc[:, [\"params\"]]\n",
        "print(column)\n",
        "\n",
        "# Extract and print the row that had the best mean test score\n",
        "best_row = cv_results_df[cv_results_df[\"rank_test_score\"] == 1]\n",
        "print(best_row)"
      ],
      "metadata": {
        "id": "v9uNlKPPZWOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the best results\n",
        "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's gridSearchCv objects have a number of parameters that provide key information on just the best square (or row in cv_results_).\n",
        "\n",
        "Three properties you will explore are:\n",
        "\n",
        "best_score_ – The score (here ROC_AUC) from the best-performing square.\n",
        "best_index_ – The index of the row in cv_results_ containing information on the best-performing square.\n",
        "best_params_ – A dictionary of the parameters that gave the best score, for example 'max_depth': 10\n",
        "The grid search object grid_rf_class is available.\n",
        "\n",
        "A dataframe (cv_results_df) has been created from the cv_results_ for you on line 6. This will help you index into the results.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Extract and print out the ROC_AUC score from the best performing square in grid_rf_class.\n",
        "Create a variable from the best-performing row by indexing into cv_results_df.\n",
        "Create a variable, best_n_estimators by extracting the n_estimators parameter from the best-performing square in grid_rf_class and print it out."
      ],
      "metadata": {
        "id": "UyJo3kogZdXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the ROC_AUC score from the best-performing square\n",
        "best_score = grid_rf_class.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Create a variable from the row related to the best-performing square\n",
        "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
        "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
        "print(best_row)\n",
        "\n",
        "# Get the n_estimators parameter from the best-performing square and print\n",
        "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
        "print(best_n_estimators)"
      ],
      "metadata": {
        "id": "0rPWuCU-Zdnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the best results\n",
        "While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object.\n",
        "\n",
        "We can access this object through the best_estimator_ property of our grid search object.\n",
        "\n",
        "Let's take a look inside the best_estimator_ property, make predictions, and generate evaluation scores. We will firstly use the default predict (giving class predictions), but then we will need to use predict_proba rather than predict to generate the roc-auc score as roc-auc needs probability scores for its calculation. We use a slice [:,1] to get probabilities of the positive class.\n",
        "\n",
        "You have available the X_test and y_test datasets to use and the grid_rf_class object from previous exercises.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Check the type of the best_estimator_ property.\n",
        "Use the best_estimator_ property to make predictions on our test set.\n",
        "Generate a confusion matrix and ROC_AUC score from our predictions."
      ],
      "metadata": {
        "id": "9c-0H9RuZlOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See what type of object the best_estimator_ property is\n",
        "print(type(grid_rf_class.best_estimator_))\n",
        "\n",
        "# Create an array of predictions directly using the best_estimator_ property\n",
        "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
        "\n",
        "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Now create a confusion matrix\n",
        "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
        "\n",
        "# Get the ROC-AUC score\n",
        "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
        "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
      ],
      "metadata": {
        "id": "AZdSeQwPZle2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomly Sample Hyperparameters\n",
        "To undertake a random search, we firstly need to undertake a random sampling of our hyperparameter space.\n",
        "\n",
        "In this exercise, you will firstly create some lists of hyperparameters that can be zipped up to a list of lists. Then you will randomly sample hyperparameter combinations in preparation for running a random search.\n",
        "\n",
        "You will use just the hyperparameters learning_rate and min_samples_leaf of the GBM algorithm to keep the example illustrative and not overly complicated.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a list of 200 values for the learning_rate hyperparameter between 0.01 and 1.5 and assign to the list learn_rate_list.\n",
        "Create a list of values between 10 and 40 inclusive for the hyperparameter min_samples_leaf and assign to the list min_samples_list.\n",
        "Combine these lists into a list of lists to sample from.\n",
        "Randomly sample 250 models from these hyperparameter combinations and print the result."
      ],
      "metadata": {
        "id": "NHZuWR-DaZ-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of values for the learning_rate hyperparameter\n",
        "learn_rate_list = list(np.linspace(0.01,1.5,200))\n",
        "\n",
        "# Create a list of values for the min_samples_leaf hyperparameter\n",
        "min_samples_list = list(range(10,41))\n",
        "\n",
        "# Combination list\n",
        "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
        "\n",
        "# Sample hyperparameter combinations for a random search.\n",
        "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
        "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
        "\n",
        "# Print the result\n",
        "print(combinations_random_chosen)"
      ],
      "metadata": {
        "id": "zeepGCF3aaQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomly Search with Random Forest\n",
        "To solidify your knowledge of random sampling, let's try a similar exercise but using different hyperparameters and a different algorithm.\n",
        "\n",
        "As before, create some lists of hyperparameters that can be zipped up to a list of lists. You will use the hyperparameters criterion, max_depth and max_features of the random forest algorithm. Then you will randomly sample hyperparameter combinations in preparation for running a random search.\n",
        "\n",
        "You will use a slightly different package for sampling in this task, random.sample().\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create lists of the values 'gini' and 'entropy' for criterion & \"auto\", \"sqrt\", \"log2\", None for max_features.\n",
        "Create a list of values between 3 and 55 inclusive for the hyperparameter max_depth and assign to the list max_depth_list. Remember that range(N,M) will create a list from N to M-1.\n",
        "Combine these lists into a list of lists to sample from using product().\n",
        "Randomly sample 150 models from the combined list and print the result."
      ],
      "metadata": {
        "id": "lx4ZLg6ZalWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create lists for criterion and max_features\n",
        "criterion_list = [\"gini\", \"entropy\"]\n",
        "max_feature_list = [\"auto\", \"sqrt\", \"log2\", None]\n",
        "\n",
        "# Create a list of values for the max_depth hyperparameter\n",
        "max_depth_list = list(range(3,56))\n",
        "\n",
        "# Combination list\n",
        "combinations_list = [list(x) for x in product(criterion_list, max_feature_list, max_depth_list)]\n",
        "\n",
        "# Sample hyperparameter combinations for a random search\n",
        "combinations_random_chosen = random.sample(combinations_list, 150)\n",
        "\n",
        "# Print the result\n",
        "print(combinations_random_chosen)"
      ],
      "metadata": {
        "id": "Ra8oiyaTalyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing a Random Search\n",
        "Visualizing the search space of random search allows you to easily see the coverage of this technique and therefore allows you to see the effect of your sampling on the search space.\n",
        "\n",
        "In this exercise you will use several different samples of hyperparameter combinations and produce visualizations of the search space.\n",
        "\n",
        "The function sample_and_visualize_hyperparameters() takes a single argument (number of combinations to sample) and then randomly samples hyperparameter combinations, just like you did in the last exercise! The function will then visualize the combinations.\n",
        "\n",
        "If you want to see the function definition, you can use Python's handy inspect library, like so:\n",
        "\n",
        "print(inspect.getsource(sample_and_visualize_hyperparameters))\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Confirm how many possible hyperparameter combinations there are in combinations_list by assigning to the variable number_combs and print this out.\n",
        "Sample and visualize 50, 500 and 1500 combinations. You will use a loop for succinctness. What do you notice about the visualization?\n",
        "Now sample and visualize the entire set of combinations. You have already made a variable to assist with this. What does this look like?"
      ],
      "metadata": {
        "id": "Bj2dUlhPawqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm how many hyperparameter combinations & print\n",
        "number_combs = len(combinations_list)\n",
        "print(number_combs)\n",
        "\n",
        "# Sample and visualise specified combinations\n",
        "for x in [50, 500, 1500]:\n",
        "    sample_and_visualize_hyperparameters(x)\n",
        "\n",
        "# Sample all the hyperparameter combinations & visualise\n",
        "sample_and_visualize_hyperparameters(number_combs)"
      ],
      "metadata": {
        "id": "EoytlmdUaxCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The RandomizedSearchCV Object\n",
        "Just like the GridSearchCV library from Scikit Learn, RandomizedSearchCV provides many useful features to assist with efficiently undertaking a random search. You're going to create a RandomizedSearchCV object, making the small adjustment needed from the GridSearchCV object.\n",
        "\n",
        "The desired options are:\n",
        "\n",
        "A default Gradient Boosting Classifier Estimator\n",
        "5-fold cross validation\n",
        "Use accuracy to score the models\n",
        "Use 4 cores for processing in parallel\n",
        "Ensure you refit the best model and return training scores\n",
        "Randomly sample 10 models\n",
        "The hyperparameter grid should be for learning_rate (150 values between 0.1 and 2) and min_samples_leaf (all values between and including 20 and 64).\n",
        "\n",
        "You will have available X_train & y_train datasets.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a parameter grid as specified in the context above.\n",
        "Create a RandomizedSearchCV object as outlined in the context above.\n",
        "Fit the RandomizedSearchCV object to the training data.\n",
        "Print the values chosen by the modeling process for both hyperparameters."
      ],
      "metadata": {
        "id": "ZLH-yBxwcLES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parameter grid\n",
        "param_grid = {'learning_rate': np.linspace(0.1, 2, 150), 'min_samples_leaf': list(range(20, 65))}\n",
        "\n",
        "# Create a random search object\n",
        "random_GBM_class = RandomizedSearchCV(\n",
        "    estimator = GradientBoostingClassifier(),\n",
        "    param_distributions = param_grid,\n",
        "    n_iter = 10,\n",
        "    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)\n",
        "\n",
        "# Fit to the training data\n",
        "random_GBM_class.fit(X_train, y_train)\n",
        "\n",
        "# Print the values used for both hyperparameters\n",
        "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
        "print(random_GBM_class.cv_results_['param_min_samples_leaf'])"
      ],
      "metadata": {
        "id": "QyjnWXXMcLUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomSearchCV in Scikit Learn\n",
        "Let's practice building a RandomizedSearchCV object using Scikit Learn.\n",
        "\n",
        "The hyperparameter grid should be for max_depth (all values between and including 5 and 25) and max_features ('auto' and 'sqrt').\n",
        "\n",
        "The desired options for the RandomizedSearchCV object are:\n",
        "\n",
        "A RandomForestClassifier Estimator with n_estimators of 80.\n",
        "3-fold cross validation (cv)\n",
        "Use roc_auc to score the models\n",
        "Use 4 cores for processing in parallel (n_jobs)\n",
        "Ensure you refit the best model and return training scores\n",
        "Only sample 5 models for efficiency (n_iter)\n",
        "X_train & y_train datasets are loaded for you.\n",
        "\n",
        "Remember, to extract the chosen hyperparameters these are found in cv_results_ with a column per hyperparameter. For example, the column for the hyperparameter criterion would be param_criterion.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Create a hyperparameter grid as specified in the context above.\n",
        "Create a RandomizedSearchCV object as outlined in the context above.\n",
        "Fit the RandomizedSearchCV object to the training data.\n",
        "Index into the cv_results_ object to print the values chosen by the modeling process for both hyperparameters (max_depth and max_features)."
      ],
      "metadata": {
        "id": "JG8r_TGXcWWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parameter grid\n",
        "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']}\n",
        "\n",
        "# Create a random search object\n",
        "random_rf_class = RandomizedSearchCV(\n",
        "    estimator = RandomForestClassifier(n_estimators=80),\n",
        "    param_distributions = param_grid, n_iter = 5,\n",
        "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True)\n",
        "\n",
        "# Fit to the training data\n",
        "random_rf_class.fit(X_train, y_train)\n",
        "\n",
        "# Print the values used for both hyperparameters\n",
        "print(random_rf_class.cv_results_['param_max_depth'])\n",
        "print(random_rf_class.cv_results_['param_max_features'])"
      ],
      "metadata": {
        "id": "-BX1JETGcWkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid and Random Search Side by Side\n",
        "Visualizing the search space of random and grid search together allows you to easily see the coverage that each technique has and therefore brings to life their specific advantages and disadvantages.\n",
        "\n",
        "In this exercise, you will sample hyperparameter combinations in a grid search way as well as a random search way, then plot these to see the difference.\n",
        "\n",
        "You will have available:\n",
        "\n",
        "combinations_list which is a list of combinations of learn_rate and min_samples_leaf for this algorithm\n",
        "The function visualize_search() which will make your hyperparameter combinations into X and Y coordinates and plot both grid and random search combinations on the same graph. It takes as input two lists of hyperparameter combinations.\n",
        "If you wish to view the visualize_search() function definition, you can run this code:\n",
        "```\n",
        "import inspect\n",
        "print(inspect.getsource(visualize_search))\n",
        "```\n",
        "Instructions 1/4\n",
        "1 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Sample (by slicing) 300 hyperparameter combinations for a grid search from combinations_list into two lists and print the result."
      ],
      "metadata": {
        "id": "f2SY4ltjc0sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample grid coordinates\n",
        "grid_combinations_chosen = combinations_list[0:300]\n",
        "\n",
        "# Print result\n",
        "print(grid_combinations_chosen)"
      ],
      "metadata": {
        "id": "ZtwpSnCXc1AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/4\n",
        "18 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Let's randomly sample too. Create a list of every index in combinations_list to sample from using range()\n",
        "Use np.random.choice() to sample 300 combinations. The first two arguments are a list to sample from and the number of samples."
      ],
      "metadata": {
        "id": "drEahXfQc8yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample grid coordinates\n",
        "grid_combinations_chosen = combinations_list[0:300]\n",
        "\n",
        "# Create a list of sample indexes\n",
        "sample_indexes = list(range(0,len(combinations_list)))\n",
        "\n",
        "# Randomly sample 300 indexes\n",
        "random_indexes = np.random.choice(sample_indexes, 300, replace=False)"
      ],
      "metadata": {
        "id": "Cg1YaQ7fc89o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Now use the list of random indexes to index into combinations_list using a list comprehension."
      ],
      "metadata": {
        "id": "RKzy3-qydC_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample grid coordinates\n",
        "grid_combinations_chosen = combinations_list[0:300]\n",
        "\n",
        "# Create a list of sample indexes\n",
        "sample_indexes = list(range(0,len(combinations_list)))\n",
        "\n",
        "# Randomly sample 300 indexes\n",
        "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
        "\n",
        "# Use indexes to create random sample\n",
        "random_combinations_chosen = [combinations_list[index] for index in random_indexes]"
      ],
      "metadata": {
        "id": "zfoKw7_-dDKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Use the provided visualize_search() function to visualize the two sampling methodologies. The first argument is your grid combinations, the second argument is the random combinations you created."
      ],
      "metadata": {
        "id": "mbd4-kxadH8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample grid coordinates\n",
        "grid_combinations_chosen = combinations_list[0:300]\n",
        "\n",
        "# Create a list of sample indexes\n",
        "sample_indexes = list(range(0,len(combinations_list)))\n",
        "\n",
        "# Randomly sample 300 indexes\n",
        "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
        "\n",
        "# Use indexes to create random sample\n",
        "random_combinations_chosen = [combinations_list[index] for index in random_indexes]\n",
        "\n",
        "# Call the function to produce the visualization\n",
        "visualize_search(grid_combinations_chosen, random_combinations_chosen)"
      ],
      "metadata": {
        "id": "DKT3abvtdIIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# /\n",
        "/\n",
        "Daily XP\n",
        "3878\n",
        "Exercise\n",
        "Exercise\n",
        "Visualizing Coarse to Fine\n",
        "You're going to undertake the first part of a Coarse to Fine search. This involves analyzing the results of an initial random search that took place over a large search space, then deciding what would be the next logical step to make your hyperparameter search finer.\n",
        "\n",
        "You have available:\n",
        "\n",
        "combinations_list - a list of the possible hyperparameter combinations the random search was undertaken on.\n",
        "results_df - a DataFrame that has each hyperparameter combination and the resulting accuracy of all 500 trials. Each hyperparameter is a column, with the header the hyperparameter name.\n",
        "visualize_hyperparameter() - a function that takes in a column of the DataFrame (as a string) and produces a scatter plot of this column's values compared to the accuracy scores. An example call of the function would be visualize_hyperparameter('accuracy')\n",
        "If you wish to view the visualize_hyperparameter() function definition, you can run this code:\n",
        "\n",
        "import inspect\n",
        "print(inspect.getsource(visualize_hyperparameter))\n",
        "Instructions\n",
        "100 XP\n",
        "Confirm (by printing out) the size of the combinations_list, justifying the need to start with a random search.\n",
        "Sort the results_df by accuracy values and print the top 10 rows. Are there clear insights? Beware a small sample size!\n",
        "Confirm (by printing out) which hyperparameters were used in this search. These are the column names in results_df.\n",
        "Call visualize_hyperparameter() with each hyperparameter in turn (max_depth, min_samples_leaf, learn_rate). Are there any trends?"
      ],
      "metadata": {
        "id": "HQ91dDBvd24D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the size of the combinations_list\n",
        "print(len(combinations_list))\n",
        "\n",
        "# Sort the results_df by accuracy and print the top 10 rows\n",
        "print(results_df.sort_values(by='accuracy', ascending=False).head(10))\n",
        "\n",
        "# Confirm which hyperparameters were used in this search\n",
        "print(results_df.columns)\n",
        "\n",
        "# Call visualize_hyperparameter() with each hyperparameter in turn\n",
        "visualize_hyperparameter('max_depth')\n",
        "visualize_hyperparameter('min_samples_leaf')\n",
        "visualize_hyperparameter('learn_rate')"
      ],
      "metadata": {
        "id": "pWNV5Dhwd3RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coarse to Fine Iterations\n",
        "You will now visualize the first random search undertaken, construct a tighter grid and check the results. You will have available:\n",
        "\n",
        "results_df - a DataFrame that has the hyperparameter combination and the resulting accuracy of all 500 trials. Only the hyperparameters that had the strongest visualizations from the previous exercise are included (max_depth and learn_rate)\n",
        "visualize_first() - This function takes no arguments but will visualize each of your hyperparameters against accuracy for your first random search.\n",
        "If you wish to view the visualize_first() (or the visualize_second()) function definition, you can run this code:\n",
        "```\n",
        "import inspect\n",
        "print(inspect.getsource(visualize_first))\n",
        "```\n",
        "Instructions 1/3\n",
        "1 XP\n",
        "2\n",
        "3\n",
        "Use the visualize_first() function to check the values of max_depth and learn_rate that tend to perform better. A convenient red line will be added to make this explicit.\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZQDHWr3eBJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the provided function to visualize the first results\n",
        "visualize_first()"
      ],
      "metadata": {
        "id": "jLmlqKXVeDRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Now create a more narrow grid search, testing for max_depth values between 1 and 20 and for 50 learning rates between 0.001 and 1.\n"
      ],
      "metadata": {
        "id": "kGGwpG8WeGQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the provided function to visualize the first results\n",
        "# visualize_first()\n",
        "\n",
        "# Create some combinations lists & combine\n",
        "max_depth_list = list(range(1, 21))\n",
        "learn_rate_list = np.linspace(0.001, 1, 50)"
      ],
      "metadata": {
        "id": "ICU6avsveGb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "0 XP\n",
        "3\n",
        "We ran the 1,000 model grid search in the background based on those new combinations. Now use the visualize_second() function to visualize the second iteration (grid search) and see if there is any improved results. This function takes no arguments, just run it in-place to generate the plots!"
      ],
      "metadata": {
        "id": "0x_hJ_-deQfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the provided function to visualize the first results\n",
        "# visualize_first()\n",
        "\n",
        "# Create some combinations lists & combine:\n",
        "max_depth_list = list(range(1,21))\n",
        "learn_rate_list = np.linspace(0.001,1,50)\n",
        "\n",
        "# Call the function to visualize the second results\n",
        "visualize_second()"
      ],
      "metadata": {
        "id": "m2dQ5ADPeQoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes Rule in Python\n",
        "In this exercise you will undertake a practical example of setting up Bayes formula, obtaining new evidence and updating your 'beliefs' in order to get a more accurate result. The example will relate to the likelihood that someone will close their account for your online software product.\n",
        "\n",
        "These are the probabilities we know:\n",
        "\n",
        "7% (0.07) of people are likely to close their account next month\n",
        "15% (0.15) of people with accounts are unhappy with your product (you don't know who though!)\n",
        "35% (0.35) of people who are likely to close their account are unhappy with your product\n",
        "Instructions 1/3\n",
        "1 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Assign the different probabilities (as decimals) to variables. p_unhappy is the likelihood someone is unhappy, p_unhappy_close is the probability that someone is unhappy with the product, given they are going to close their account."
      ],
      "metadata": {
        "id": "8n1bcW9bfF9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign probabilities to variables\n",
        "p_unhappy = 0.15\n",
        "p_unhappy_close = 0.35"
      ],
      "metadata": {
        "id": "pNn9Tgd9fGdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Assign the probability that someone will close their account next month to the variable p_close as a decimal.\n"
      ],
      "metadata": {
        "id": "IaQie-JafJFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign probabilities to variables\n",
        "p_unhappy = 0.15\n",
        "p_unhappy_close = 0.35\n",
        "\n",
        "# Probabiliy someone will close\n",
        "p_close = 0.07"
      ],
      "metadata": {
        "id": "guF5npmbfJQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "You interview one of your customers and discover they are unhappy. What is the probability they will close their account, now that you know this evidence? Assign the result to p_close_unhappy and print it."
      ],
      "metadata": {
        "id": "d9fNl5STfM9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign probabilities to variables\n",
        "p_unhappy = 0.15\n",
        "p_unhappy_close = 0.35\n",
        "\n",
        "# Probabiliy someone will close\n",
        "p_close = 0.07\n",
        "\n",
        "# Probability unhappy person will close\n",
        "p_close_unhappy = (p_unhappy_close * p_close) / p_unhappy\n",
        "print(p_close_unhappy)"
      ],
      "metadata": {
        "id": "bKt4pOSXfNFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Hyperparameter tuning with Hyperopt\n",
        "In this example you will set up and run a Bayesian hyperparameter optimization process using the package Hyperopt (already imported as hp for you). You will set up the domain (which is similar to setting up the grid for a grid search), then set up the objective function. Finally, you will run the optimizer over 20 iterations.\n",
        "\n",
        "You will need to set up the domain using values:\n",
        "\n",
        "max_depth using quniform distribution (between 2 and 10, increasing by 2)\n",
        "learning_rate using uniform distribution (0.001 to 0.9)\n",
        "Note that for the purpose of this exercise, this process was reduced in data sample size and hyperopt & GBM iterations. If you are trying out this method by yourself on your own machine, try a larger search space, more trials, more cvs and a larger dataset size to really see this in action!\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Set up a space dictionary using the domain mentioned above.\n",
        "Set up the objective function using a gradient boosting classifier.\n",
        "Run the algorithm for 20 evaluations (just use the default, suggested algorithm from the slides)."
      ],
      "metadata": {
        "id": "5LxDdpBrfs5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up space dictionary with specified hyperparameters\n",
        "space = {'max_depth': hp.quniform('max_depth', 2, 10, 2),'learning_rate': hp.uniform('learning_rate', 0.001, 0.9)}\n",
        "\n",
        "# Set up objective function\n",
        "def objective(params):\n",
        "    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n",
        "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params)\n",
        "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=2, n_jobs=4).mean()\n",
        "    loss = 1 - best_score\n",
        "    return loss\n",
        "\n",
        "# Run the algorithm\n",
        "best = fmin(fn=objective,space=space, max_evals=20, rstate=np.random.default_rng(42), algo=tpe.suggest)\n",
        "print(best)"
      ],
      "metadata": {
        "id": "bli2-FiSftGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genetic Hyperparameter Tuning with TPOT\n",
        "You're going to undertake a simple example of genetic hyperparameter tuning. TPOT is a very powerful library that has a lot of features. You're just scratching the surface in this lesson, but you are highly encouraged to explore in your own time.\n",
        "\n",
        "This is a very small example. In real life, TPOT is designed to be run for many hours to find the best model. You would have a much larger population and offspring size as well as hundreds more generations to find a good model.\n",
        "\n",
        "You will create the estimator, fit the estimator to the training data and then score this on the test data.\n",
        "\n",
        "For this example we wish to use:\n",
        "\n",
        "3 generations\n",
        "4 in the population size\n",
        "3 offspring in each generation\n",
        "accuracy for scoring\n",
        "A random_state of 2 has been set for consistency of results.\n",
        "\n",
        "Instructions\n",
        "100 XP\n",
        "Assign the values outlined in the context to the inputs for tpot_clf.\n",
        "Create the tpot_clf classifier with the correct inputs.\n",
        "Fit the classifier to the training data (X_train & y_train are available in your workspace).\n",
        "Use the fitted classifier to score on the test set (X_test & y_test are available in your workspace)."
      ],
      "metadata": {
        "id": "lG0ZaSpagTUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the values outlined to the inputs\n",
        "number_generations = 3\n",
        "population_size = 4\n",
        "offspring_size = 3\n",
        "scoring_function = 'accuracy'\n",
        "\n",
        "# Create the tpot classifier\n",
        "tpot_clf = TPOTClassifier(generations=number_generations, population_size=population_size,\n",
        "                          offspring_size=offspring_size, scoring=scoring_function,\n",
        "                          verbosity=2, random_state=2, cv=2)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "tpot_clf.fit(X_train, y_train)\n",
        "\n",
        "# Score on the test set\n",
        "print(tpot_clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "FxdSumONgThL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysing TPOT's stability\n",
        "You will now see the random nature of TPOT by constructing the classifier with different random states and seeing what model is found to be best by the algorithm. This assists to see that TPOT is quite unstable when not run for a reasonable amount of time.\n",
        "\n",
        "Instructions 1/3\n",
        "1 XP\n",
        "Create the TPOT classifier, fit to the data and score using a random_state of 42."
      ],
      "metadata": {
        "id": "OtnQJS6PgZut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tpot classifier\n",
        "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
        "                          verbosity=2, random_state=42)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "tpot_clf.fit(X_train, y_train)\n",
        "\n",
        "# Score on the test set\n",
        "print(tpot_clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "YBuJGzGwgZ8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 2/3\n",
        "\n",
        "Now try using a random_state of 122. The numbers don't mean anything special, but should produce different results."
      ],
      "metadata": {
        "id": "tIZ2XIZtgc7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tpot classifier\n",
        "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
        "                          verbosity=2, random_state=122)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "tpot_clf.fit(X_train, y_train)\n",
        "\n",
        "# Score on the test set\n",
        "print(tpot_clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "EdlbaKKLgeDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions 3/3\n",
        "\n",
        "\n",
        "Finally try using the random_state of 99. See how there is a different result again?"
      ],
      "metadata": {
        "id": "cgY2Qsoggl8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the tpot classifier\n",
        "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
        "                          verbosity=2, random_state=99)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "tpot_clf.fit(X_train, y_train)\n",
        "\n",
        "# Score on the test set\n",
        "print(tpot_clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "VljWb4KrgmmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Module End ---"
      ],
      "metadata": {
        "id": "qmUgigS4gybq"
      }
    }
  ]
}